{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.12","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"import json\nfrom datasets import Dataset, load_dataset, load_metric\nimport pandas as pd\nwith open('/kaggle/input/uitds-fever-ise-publist-test/ise-dsc01-train_new.json', 'r') as file:\n    datasets = json.load(file)","metadata":{"execution":{"iopub.status.busy":"2023-11-04T05:28:25.565305Z","iopub.execute_input":"2023-11-04T05:28:25.566162Z","iopub.status.idle":"2023-11-04T05:28:27.408298Z","shell.execute_reply.started":"2023-11-04T05:28:25.566129Z","shell.execute_reply":"2023-11-04T05:28:27.407259Z"},"trusted":true},"execution_count":46,"outputs":[]},{"cell_type":"code","source":"from huggingface_hub import notebook_login\n\nnotebook_login()","metadata":{"execution":{"iopub.status.busy":"2023-11-04T04:40:23.402877Z","iopub.execute_input":"2023-11-04T04:40:23.403511Z","iopub.status.idle":"2023-11-04T04:40:23.430168Z","shell.execute_reply.started":"2023-11-04T04:40:23.403475Z","shell.execute_reply":"2023-11-04T04:40:23.429268Z"},"trusted":true},"execution_count":2,"outputs":[{"output_type":"display_data","data":{"text/plain":"VBox(children=(HTML(value='<center> <img\\nsrc=https://huggingface.co/front/assets/huggingface_logo-noborder.sv…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2751651260d64c7ea39ecd061c5d3359"}},"metadata":{}}]},{"cell_type":"markdown","source":"## Processed_train data","metadata":{}},{"cell_type":"code","source":"import re\n\n\ndef remove_author_from_context(context, author):\n    if context.endswith(author):\n        context = context[: -len(author)].strip()\n    return context\n\ndef processed_based_data(datasets):\n    new_datasets = {}\n    for key, item in datasets.items():\n        context = item['context']\n        author_pattern = r\"\\n\\n(.+)$\"\n        author_match = re.search(author_pattern, context)\n    #     print(author_match)\n\n        if author_match:\n            author = author_match.group(1)\n    #         print(author,\"\\n\")\n            if len(author) < 50:\n                item['context'] = remove_author_from_context(context, author)\n    #             print(author,'\\n')\n            if item['evidence'] is None:                  \n                item['context'] = re.sub(r'\\n\\n', ' ', item['context'])\n                item['context'] = \" \".join(item['context'].split())\n\n                new_datasets[key] = item\n                continue\n            if author in item['evidence']:\n                continue\n\n            item['evidence'] = re.sub(r'\\n\\n', ' ', item['evidence'])\n            item['evidence'] = \" \".join(item['evidence'].split())\n\n            item['context'] = re.sub(r'\\n\\n', ' ', item['context'])\n            item['context'] = \" \".join(item['context'].split())\n\n            new_datasets[key] = item\n        else:\n            # If no author found, just process evidence (if exists) and context\n            if item['evidence'] is not None:\n                item['evidence'] = re.sub(r'\\n\\n', ' ', item['evidence'])\n                item['evidence'] = \" \".join(item['evidence'].split())\n\n            item['context'] = re.sub(r'\\n\\n', ' ', item['context'])\n            item['context'] = \" \".join(item['context'].split())\n\n            new_datasets[key] = item\n    return new_datasets\n","metadata":{"execution":{"iopub.status.busy":"2023-11-04T05:28:28.027307Z","iopub.execute_input":"2023-11-04T05:28:28.027685Z","iopub.status.idle":"2023-11-04T05:28:28.039460Z","shell.execute_reply.started":"2023-11-04T05:28:28.027657Z","shell.execute_reply":"2023-11-04T05:28:28.038430Z"},"trusted":true},"execution_count":47,"outputs":[]},{"cell_type":"code","source":"def extract_sentences_offcial(context):\n    sentences = re.split(r'(?<![A-Z])\\.\\s+(?=[0, 1, 2, 3, 4, 5, 6, 7, 8, 9, A, Á, À, Ạ, Ả, Ã, Ậ, Ấ, Ầ, Ẫ, Ẩ, Â, Ặ, Ắ, Ằ, Ẵ, Ẳ, Ă, B, C, D, Đ, E, É, È, Ẹ, Ẻ, Ẽ, Ê, Ế, Ề, Ệ, Ể, Ễ, F, J, W, Z G, H, I, Ị, Ỉ, Í, Ì, Ĩ, K, L, M, N, O, Ó, Ỏ, Ò, Ọ, Õ, Ô, Ố, Ồ, Ỗ, Ộ, Ổ, Ơ, Ở, Ợ, Ờ, Ớ, Ỡ, P, Q, R, S, T, U, Ù, Ú, Ụ, Ủ, Ũ, Ư, Ứ, Ừ, Ử, Ự, Ữ, V, X, Y, Ỷ, Ỳ, Ý, Ỹ, Ỵ, \\\\\",“, \\-,*])', context)\n    context_sentences = [sentence.strip() for sentence in sentences if sentence.strip()]  # Tách các câu trong context\n    return context_sentences","metadata":{"execution":{"iopub.status.busy":"2023-11-04T05:28:28.288994Z","iopub.execute_input":"2023-11-04T05:28:28.289761Z","iopub.status.idle":"2023-11-04T05:28:28.295755Z","shell.execute_reply.started":"2023-11-04T05:28:28.289725Z","shell.execute_reply":"2023-11-04T05:28:28.294748Z"},"trusted":true},"execution_count":48,"outputs":[]},{"cell_type":"code","source":"datasets = processed_based_data(datasets)","metadata":{"execution":{"iopub.status.busy":"2023-11-04T05:28:29.025779Z","iopub.execute_input":"2023-11-04T05:28:29.026150Z","iopub.status.idle":"2023-11-04T05:28:35.240401Z","shell.execute_reply.started":"2023-11-04T05:28:29.026117Z","shell.execute_reply":"2023-11-04T05:28:35.239587Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"for key, item in datasets.items():\n    item['id'] = key\n    item['context'] = item['context'].replace(\"…\",\"... \")\n    item['context'] = item['context'].replace(\"\\\"\",\" \\\"\")\n    item['context'] = item['context'].replace(\"Dr\",\"DR\")\n    \n    context = item['context']\n#     context = context.replace(\"…\",\". \")\n#     if item['evidence'] is not None:\n#         item['evidence_start'] = context.find(item['evidence'])","metadata":{"execution":{"iopub.status.busy":"2023-11-04T05:28:35.242221Z","iopub.execute_input":"2023-11-04T05:28:35.242525Z","iopub.status.idle":"2023-11-04T05:28:35.492129Z","shell.execute_reply.started":"2023-11-04T05:28:35.242498Z","shell.execute_reply":"2023-11-04T05:28:35.491099Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"len(datasets)","metadata":{"execution":{"iopub.status.busy":"2023-11-04T05:28:35.493284Z","iopub.execute_input":"2023-11-04T05:28:35.493599Z","iopub.status.idle":"2023-11-04T05:28:35.500032Z","shell.execute_reply.started":"2023-11-04T05:28:35.493571Z","shell.execute_reply":"2023-11-04T05:28:35.499049Z"},"trusted":true},"execution_count":51,"outputs":[{"execution_count":51,"output_type":"execute_result","data":{"text/plain":"37403"},"metadata":{}}]},{"cell_type":"code","source":"# datasets['7125']","metadata":{"execution":{"iopub.status.busy":"2023-11-04T05:28:35.502101Z","iopub.execute_input":"2023-11-04T05:28:35.502418Z","iopub.status.idle":"2023-11-04T05:28:35.511304Z","shell.execute_reply.started":"2023-11-04T05:28:35.502391Z","shell.execute_reply":"2023-11-04T05:28:35.510538Z"},"trusted":true},"execution_count":52,"outputs":[]},{"cell_type":"code","source":"# data = datasets['41604']","metadata":{"execution":{"iopub.status.busy":"2023-11-04T05:28:35.512500Z","iopub.execute_input":"2023-11-04T05:28:35.513049Z","iopub.status.idle":"2023-11-04T05:28:35.523410Z","shell.execute_reply.started":"2023-11-04T05:28:35.513015Z","shell.execute_reply":"2023-11-04T05:28:35.522535Z"},"trusted":true},"execution_count":53,"outputs":[]},{"cell_type":"code","source":"# temp = extract_sentences_offcial(data['context'])","metadata":{"execution":{"iopub.status.busy":"2023-11-04T05:28:35.524478Z","iopub.execute_input":"2023-11-04T05:28:35.525003Z","iopub.status.idle":"2023-11-04T05:28:35.535864Z","shell.execute_reply.started":"2023-11-04T05:28:35.524977Z","shell.execute_reply":"2023-11-04T05:28:35.534822Z"},"trusted":true},"execution_count":54,"outputs":[]},{"cell_type":"code","source":"# temp","metadata":{"execution":{"iopub.status.busy":"2023-11-04T05:28:35.536885Z","iopub.execute_input":"2023-11-04T05:28:35.537184Z","iopub.status.idle":"2023-11-04T05:28:35.546871Z","shell.execute_reply.started":"2023-11-04T05:28:35.537160Z","shell.execute_reply":"2023-11-04T05:28:35.546026Z"},"trusted":true},"execution_count":55,"outputs":[]},{"cell_type":"markdown","source":"* delete claim có trong context nhưng evidence không phải câu đó","metadata":{}},{"cell_type":"code","source":"keys_to_delete = []\nfor key, item in datasets.items():\n    if item['evidence'] is None:\n        continue\n    if item['claim'] in item['context'] and item['claim'] not in item['evidence']:\n        keys_to_delete.append(key)\n\nfor key in keys_to_delete:\n    del datasets[key]","metadata":{"execution":{"iopub.status.busy":"2023-11-04T05:28:35.547810Z","iopub.execute_input":"2023-11-04T05:28:35.548081Z","iopub.status.idle":"2023-11-04T05:28:35.619343Z","shell.execute_reply.started":"2023-11-04T05:28:35.548058Z","shell.execute_reply":"2023-11-04T05:28:35.618602Z"},"trusted":true},"execution_count":56,"outputs":[]},{"cell_type":"code","source":"len(datasets)","metadata":{"execution":{"iopub.status.busy":"2023-11-04T05:28:35.620574Z","iopub.execute_input":"2023-11-04T05:28:35.620913Z","iopub.status.idle":"2023-11-04T05:28:35.627438Z","shell.execute_reply.started":"2023-11-04T05:28:35.620878Z","shell.execute_reply":"2023-11-04T05:28:35.626559Z"},"trusted":true},"execution_count":57,"outputs":[{"execution_count":57,"output_type":"execute_result","data":{"text/plain":"36844"},"metadata":{}}]},{"cell_type":"code","source":"refutes_data = []\nsupport_data = []\nnot_enough_data = []\n\nfor key, item in datasets.items():\n    verdict = item['verdict']\n    if verdict == 'REFUTED':\n        refutes_data.append(item)\n    elif verdict == 'SUPPORTED':\n        support_data.append(item)\n    elif verdict == 'NEI':\n        not_enough_data.append(item)","metadata":{"execution":{"iopub.status.busy":"2023-11-04T05:28:35.630502Z","iopub.execute_input":"2023-11-04T05:28:35.630772Z","iopub.status.idle":"2023-11-04T05:28:35.652659Z","shell.execute_reply.started":"2023-11-04T05:28:35.630748Z","shell.execute_reply":"2023-11-04T05:28:35.651858Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"len(refutes_data)","metadata":{"execution":{"iopub.status.busy":"2023-11-04T05:28:35.653814Z","iopub.execute_input":"2023-11-04T05:28:35.654181Z","iopub.status.idle":"2023-11-04T05:28:35.665098Z","shell.execute_reply.started":"2023-11-04T05:28:35.654145Z","shell.execute_reply":"2023-11-04T05:28:35.664335Z"},"trusted":true},"execution_count":59,"outputs":[{"execution_count":59,"output_type":"execute_result","data":{"text/plain":"12458"},"metadata":{}}]},{"cell_type":"code","source":"dataset_2_class = refutes_data[:1000] + refutes_data[5000:6000] + refutes_data[10000:11000]  + support_data[:1000] + support_data[5000:6000] + support_data[10000:11000] + not_enough_data[:1000] + not_enough_data[5000:6000]+ not_enough_data[10000:11000]","metadata":{"execution":{"iopub.status.busy":"2023-11-04T05:28:36.460616Z","iopub.execute_input":"2023-11-04T05:28:36.460986Z","iopub.status.idle":"2023-11-04T05:28:36.467110Z","shell.execute_reply.started":"2023-11-04T05:28:36.460955Z","shell.execute_reply":"2023-11-04T05:28:36.465977Z"},"trusted":true},"execution_count":60,"outputs":[]},{"cell_type":"code","source":"len(dataset_2_class)","metadata":{"execution":{"iopub.status.busy":"2023-11-04T05:28:37.864442Z","iopub.execute_input":"2023-11-04T05:28:37.865211Z","iopub.status.idle":"2023-11-04T05:28:37.870862Z","shell.execute_reply.started":"2023-11-04T05:28:37.865174Z","shell.execute_reply":"2023-11-04T05:28:37.869982Z"},"trusted":true},"execution_count":61,"outputs":[{"execution_count":61,"output_type":"execute_result","data":{"text/plain":"9000"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics.pairwise import cosine_similarity\n\ndef get_similarity_with_TF_IDF_Sklearn(claim, evidence):\n    \n    # Tạo một TF-IDF Vectorizer\n    tfidf_vectorizer = TfidfVectorizer()\n\n    # Biểu diễn câu thành vector TF-IDF\n    tfidf_matrix = tfidf_vectorizer.fit_transform([claim, evidence])\n\n    # Tính toán cosine similarity\n    cosine_sim = cosine_similarity(tfidf_matrix[0], tfidf_matrix[1])\n\n    return cosine_sim[0][0]","metadata":{"execution":{"iopub.status.busy":"2023-11-04T05:28:38.527847Z","iopub.execute_input":"2023-11-04T05:28:38.528224Z","iopub.status.idle":"2023-11-04T05:28:38.534397Z","shell.execute_reply.started":"2023-11-04T05:28:38.528193Z","shell.execute_reply":"2023-11-04T05:28:38.533236Z"},"trusted":true},"execution_count":62,"outputs":[]},{"cell_type":"code","source":"from tqdm.auto import tqdm\n# lst_nei_score_trans = []\nlst_sp_score_trans = []\nlst_rf_score_trans = []\n\n# lst_nei_score_sklearn = []\nlst_sp_score_sklearn = []\nlst_rf_score_sklearn = []\n\n\nfor i in tqdm(range(len(dataset_2_class))):\n    if dataset_2_class[i]['verdict'] == 'NEI':\n        continue\n    claim = dataset_2_class[i]['claim']\n    evidence = dataset_2_class[i]['evidence']\n#     transformers_score = get_similarity_transformers_similarity_gpu(claim, evidence, tokenizer_of_processdata, model_of_processdata)\n    sklearn_score = get_similarity_with_TF_IDF_Sklearn(claim, evidence)\n    \n#         lst_nei_score_sklearn.append(sklearn_score)\n#         lst_nei_score_trans.append(transformers_score)\n    if dataset_2_class[i]['verdict'] == 'SUPPORTED':\n        lst_sp_score_sklearn.append(sklearn_score)\n#         lst_sp_score_trans.append(transformers_score)\n    else:\n        lst_rf_score_sklearn.append(sklearn_score)\n#         lst_rf_score_trans.append(transformers_score)","metadata":{"execution":{"iopub.status.busy":"2023-11-04T05:28:39.197202Z","iopub.execute_input":"2023-11-04T05:28:39.198091Z","iopub.status.idle":"2023-11-04T05:28:55.539839Z","shell.execute_reply.started":"2023-11-04T05:28:39.198051Z","shell.execute_reply":"2023-11-04T05:28:55.538892Z"},"trusted":true},"execution_count":63,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/9000 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"56684a1d593f4934b5c8b021a671dd69"}},"metadata":{}}]},{"cell_type":"code","source":"cnt = []\nfor i in range(len(lst_sp_score_sklearn)):\n    if lst_sp_score_sklearn[i] <= min(lst_sp_score_sklearn) + 0.05:\n        cnt.append(dataset_2_class[i]['id'])\n#         print(f'------{cnt}------\\n')\n#         print(f\"ID: {df['id'][i]}\\nClaim: {df['claim'][i]}\\nEvidence: {df['evidence'][i]}\")\n#         print(f'-----------------\\n')\n","metadata":{"execution":{"iopub.status.busy":"2023-11-04T05:28:55.541650Z","iopub.execute_input":"2023-11-04T05:28:55.541943Z","iopub.status.idle":"2023-11-04T05:28:55.963658Z","shell.execute_reply.started":"2023-11-04T05:28:55.541917Z","shell.execute_reply":"2023-11-04T05:28:55.962854Z"},"trusted":true},"execution_count":64,"outputs":[]},{"cell_type":"code","source":"len(cnt)","metadata":{"execution":{"iopub.status.busy":"2023-11-04T05:28:55.964626Z","iopub.execute_input":"2023-11-04T05:28:55.964893Z","iopub.status.idle":"2023-11-04T05:28:55.971040Z","shell.execute_reply.started":"2023-11-04T05:28:55.964869Z","shell.execute_reply":"2023-11-04T05:28:55.970114Z"},"trusted":true},"execution_count":65,"outputs":[{"execution_count":65,"output_type":"execute_result","data":{"text/plain":"14"},"metadata":{}}]},{"cell_type":"code","source":"dataset_2_class =[dataset_2_class[i] for i in range(len(dataset_2_class)) if dataset_2_class[i]['id'] not in cnt]","metadata":{"execution":{"iopub.status.busy":"2023-11-04T05:28:55.974079Z","iopub.execute_input":"2023-11-04T05:28:55.974850Z","iopub.status.idle":"2023-11-04T05:28:55.988170Z","shell.execute_reply.started":"2023-11-04T05:28:55.974807Z","shell.execute_reply":"2023-11-04T05:28:55.987311Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"code","source":"len(dataset_2_class)","metadata":{"execution":{"iopub.status.busy":"2023-11-04T05:28:55.989360Z","iopub.execute_input":"2023-11-04T05:28:55.990193Z","iopub.status.idle":"2023-11-04T05:28:56.001152Z","shell.execute_reply.started":"2023-11-04T05:28:55.990165Z","shell.execute_reply":"2023-11-04T05:28:56.000292Z"},"trusted":true},"execution_count":67,"outputs":[{"execution_count":67,"output_type":"execute_result","data":{"text/plain":"8986"},"metadata":{}}]},{"cell_type":"code","source":"!pip install transformers sentence-transformers numpy","metadata":{"execution":{"iopub.status.busy":"2023-11-04T05:28:56.002409Z","iopub.execute_input":"2023-11-04T05:28:56.003160Z","iopub.status.idle":"2023-11-04T05:29:07.657867Z","shell.execute_reply.started":"2023-11-04T05:28:56.003125Z","shell.execute_reply":"2023-11-04T05:29:07.656605Z"},"trusted":true},"execution_count":68,"outputs":[{"name":"stdout","text":"Requirement already satisfied: transformers in /opt/conda/lib/python3.10/site-packages (4.33.0)\nRequirement already satisfied: sentence-transformers in /opt/conda/lib/python3.10/site-packages (2.2.2)\nRequirement already satisfied: numpy in /opt/conda/lib/python3.10/site-packages (1.23.5)\nRequirement already satisfied: filelock in /opt/conda/lib/python3.10/site-packages (from transformers) (3.12.2)\nRequirement already satisfied: huggingface-hub<1.0,>=0.15.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.16.4)\nRequirement already satisfied: packaging>=20.0 in /opt/conda/lib/python3.10/site-packages (from transformers) (21.3)\nRequirement already satisfied: pyyaml>=5.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (6.0)\nRequirement already satisfied: regex!=2019.12.17 in /opt/conda/lib/python3.10/site-packages (from transformers) (2023.6.3)\nRequirement already satisfied: requests in /opt/conda/lib/python3.10/site-packages (from transformers) (2.31.0)\nRequirement already satisfied: tokenizers!=0.11.3,<0.14,>=0.11.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.13.3)\nRequirement already satisfied: safetensors>=0.3.1 in /opt/conda/lib/python3.10/site-packages (from transformers) (0.3.3)\nRequirement already satisfied: tqdm>=4.27 in /opt/conda/lib/python3.10/site-packages (from transformers) (4.66.1)\nRequirement already satisfied: torch>=1.6.0 in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (2.0.0)\nRequirement already satisfied: torchvision in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (0.15.1)\nRequirement already satisfied: scikit-learn in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.2.2)\nRequirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (1.11.2)\nRequirement already satisfied: nltk in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (3.2.4)\nRequirement already satisfied: sentencepiece in /opt/conda/lib/python3.10/site-packages (from sentence-transformers) (0.1.99)\nRequirement already satisfied: fsspec in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (2023.9.0)\nRequirement already satisfied: typing-extensions>=3.7.4.3 in /opt/conda/lib/python3.10/site-packages (from huggingface-hub<1.0,>=0.15.1->transformers) (4.6.3)\nRequirement already satisfied: pyparsing!=3.0.5,>=2.0.2 in /opt/conda/lib/python3.10/site-packages (from packaging>=20.0->transformers) (3.0.9)\nRequirement already satisfied: sympy in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (1.12)\nRequirement already satisfied: networkx in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (3.1)\nRequirement already satisfied: jinja2 in /opt/conda/lib/python3.10/site-packages (from torch>=1.6.0->sentence-transformers) (3.1.2)\nRequirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from nltk->sentence-transformers) (1.16.0)\nRequirement already satisfied: charset-normalizer<4,>=2 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.1.0)\nRequirement already satisfied: idna<4,>=2.5 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (3.4)\nRequirement already satisfied: urllib3<3,>=1.21.1 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (1.26.15)\nRequirement already satisfied: certifi>=2017.4.17 in /opt/conda/lib/python3.10/site-packages (from requests->transformers) (2023.7.22)\nRequirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (1.3.2)\nRequirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn->sentence-transformers) (3.1.0)\nRequirement already satisfied: pillow!=8.3.*,>=5.3.0 in /opt/conda/lib/python3.10/site-packages (from torchvision->sentence-transformers) (9.5.0)\nRequirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2->torch>=1.6.0->sentence-transformers) (2.1.3)\nRequirement already satisfied: mpmath>=0.19 in /opt/conda/lib/python3.10/site-packages (from sympy->torch>=1.6.0->sentence-transformers) (1.3.0)\n","output_type":"stream"}]},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModel\nfrom sentence_transformers import SentenceTransformer, util\nimport numpy as np\nimport torch","metadata":{"execution":{"iopub.status.busy":"2023-11-04T05:29:07.659857Z","iopub.execute_input":"2023-11-04T05:29:07.660164Z","iopub.status.idle":"2023-11-04T05:29:07.665265Z","shell.execute_reply.started":"2023-11-04T05:29:07.660136Z","shell.execute_reply":"2023-11-04T05:29:07.664158Z"},"trusted":true},"execution_count":69,"outputs":[]},{"cell_type":"code","source":"phobert_model_name = \"vinai/phobert-base\"\ntokenizer = AutoTokenizer.from_pretrained(phobert_model_name)\nmodel = AutoModel.from_pretrained(phobert_model_name)","metadata":{"execution":{"iopub.status.busy":"2023-11-04T05:29:07.666446Z","iopub.execute_input":"2023-11-04T05:29:07.666712Z","iopub.status.idle":"2023-11-04T05:29:09.854141Z","shell.execute_reply.started":"2023-11-04T05:29:07.666688Z","shell.execute_reply":"2023-11-04T05:29:09.853360Z"},"trusted":true},"execution_count":70,"outputs":[{"name":"stderr","text":"Special tokens have been added in the vocabulary, make sure the associated word embeddings are fine-tuned or trained.\n","output_type":"stream"}]},{"cell_type":"code","source":"import torch\nfrom torch.cuda.amp import autocast\nfrom tqdm.auto import tqdm\n\ndef process_data_with_gpu(data, tokenizer, model, max_context_sentences=6):\n    # Đảm bảo GPU có sẵn\n    device = torch.device(\"cuda\")\n    model = model.to(device)\n\n    processed_data = []\n\n    for item in tqdm(data):\n        claim = item['claim']\n        context = item['context']\n        claim_tokens = tokenizer(claim, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n        with torch.no_grad():\n            with autocast():  # Sử dụng autocast để tận dụng hiệu suất và giảm bộ nhớ\n                claim_embedding = model(**claim_tokens).pooler_output\n\n        # Di chuyển tensors lên CPU để thực hiện các phép toán NumPy\n        claim_embedding = claim_embedding.to(\"cpu\").numpy()\n\n        # Chuyển các tensors về kiểu float32 (32-bit floating point)\n        claim_embedding = claim_embedding.astype('float32')\n        context_sentences = extract_sentences_offcial(context)# Tách các câu trong context\n        best_similarity = 0.5  # Điểm tương đồng cao nhất\n        # Câu có điểm tương đồng cao nhất\n        best_sentence = []   \n        for sentence in context_sentences:\n            # Tiến hành nhúng câu\n            similarity = []\n            sentence_tokens = tokenizer(sentence, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n            with torch.no_grad():\n                sentence_embedding = model(**sentence_tokens).pooler_output\n            sentence_embedding = sentence_embedding.to(\"cpu\").numpy()\n\n            # Chuyển các tensors về kiểu float32 (32-bit floating point)\n            sentence_embedding = sentence_embedding.astype('float32')\n\n            # Tính độ tương tự với câu claim\n            similarity_score = util.pytorch_cos_sim(claim_embedding, sentence_embedding)\n            if len(context_sentences) <= max_context_sentences:\n                similarity.append(similarity_score.item())\n                similarity.append(sentence)\n                best_sentence.append(similarity)\n                continue \n\n            if similarity_score.item() > best_similarity:\n                similarity.append(similarity_score.item())\n                similarity.append(sentence)\n                best_sentence.append(similarity)\n\n        sorted_data = sorted(best_sentence, key=lambda x: x[0], reverse=True)\n        top_data = sorted_data\n        if len(top_data) <=6:\n            context_end = context\n        else:\n            context_end = \". \".join([item[1] for item in top_data])\n        \n        data = {\n            \"context\": context_end,\n            \"claim\": claim,\n            \"verdict\": item['verdict'],\n            \"evidence\": item['evidence'],\n            \"id\": item['id']\n        }\n        \n        processed_data.append(data)\n\n    return processed_data\n","metadata":{"execution":{"iopub.status.busy":"2023-11-04T05:29:09.855738Z","iopub.execute_input":"2023-11-04T05:29:09.856028Z","iopub.status.idle":"2023-11-04T05:29:09.870191Z","shell.execute_reply.started":"2023-11-04T05:29:09.856001Z","shell.execute_reply":"2023-11-04T05:29:09.869215Z"},"trusted":true},"execution_count":71,"outputs":[]},{"cell_type":"code","source":"dataset_2_class = process_data_with_gpu(dataset_2_class, tokenizer, model)","metadata":{"execution":{"iopub.status.busy":"2023-11-04T05:29:09.873136Z","iopub.execute_input":"2023-11-04T05:29:09.873510Z","iopub.status.idle":"2023-11-04T06:08:07.822803Z","shell.execute_reply.started":"2023-11-04T05:29:09.873472Z","shell.execute_reply":"2023-11-04T06:08:07.821879Z"},"trusted":true},"execution_count":72,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/8986 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"f2f14d1f98de441f95e5265a8b9a1124"}},"metadata":{}}]},{"cell_type":"code","source":"for item in dataset_2_class:\n    if item['evidence'] is None:\n        continue\n    if item['evidence'] not in item['context']:\n        item['context'] = item['context'] + \". \"+ item['evidence']\n    context = item['context']\n    item['evidence_start'] = context.find(item['evidence'])","metadata":{"execution":{"iopub.status.busy":"2023-11-04T06:08:09.469809Z","iopub.execute_input":"2023-11-04T06:08:09.470194Z","iopub.status.idle":"2023-11-04T06:08:09.497739Z","shell.execute_reply.started":"2023-11-04T06:08:09.470158Z","shell.execute_reply":"2023-11-04T06:08:09.496904Z"},"trusted":true},"execution_count":73,"outputs":[]},{"cell_type":"code","source":"# dataset_2_class[0]","metadata":{"execution":{"iopub.status.busy":"2023-11-04T05:26:25.819063Z","iopub.execute_input":"2023-11-04T05:26:25.819450Z","iopub.status.idle":"2023-11-04T05:26:25.823720Z","shell.execute_reply.started":"2023-11-04T05:26:25.819414Z","shell.execute_reply":"2023-11-04T05:26:25.822737Z"},"trusted":true},"execution_count":45,"outputs":[]},{"cell_type":"code","source":"# import pandas as pd\n\n# # ... Your previous code to calculate seq_len ...\n\n# combined_text = []\n# for item in dataset_2_class:\n#     combined_text.append(item['context'])\n# seq_len = [len(i.split()) for i in combined_text]\n# chart = pd.Series(seq_len)\n# print(chart)\n# chart.hist(bins=30)\n# min_seq_len = min(seq_len)\n# print(\"Minimum sequence length:\", min_seq_len)\n# # Find and print the text strings with the minimum sequence length along with their indices\n# min_seq_strings = [(i, s) for i, s in enumerate(combined_text) if len(s.split()) == min_seq_len]\n# for i, s in min_seq_strings:\n#     print(f\"Index: {i}, Text with the minimum sequence length:\", s)\n\n# # Filter and keep data entries with a sequence length greater than or equal to 50\n# processed_data = [item for i, item in enumerate(dataset_2_class) if seq_len[i] >= 120]\n\n# # Print the first few entries in filtered_processed_data as an example\n# for i, item in enumerate(processed_data[:5]):\n#     print(f\"Filtered Entry {i + 1}:\")\n#     print(\"Context:\", item['context'])\n#     print(\"Claim:\", item['claim'])\n#     print()\n","metadata":{"execution":{"iopub.status.busy":"2023-11-04T06:08:15.571337Z","iopub.execute_input":"2023-11-04T06:08:15.572202Z","iopub.status.idle":"2023-11-04T06:08:15.576842Z","shell.execute_reply.started":"2023-11-04T06:08:15.572169Z","shell.execute_reply":"2023-11-04T06:08:15.575902Z"},"trusted":true},"execution_count":75,"outputs":[]},{"cell_type":"code","source":"combined_text = []\nfor item in processed_data:\n    combined_text.append(item['context'] + \" \" + item['claim'])\nseq_len = [len(i.split()) for i in combined_text]\nchart = pd.Series(seq_len)\nprint(chart)\nchart.hist(bins=30)\nmin_seq_len = min(seq_len)\nprint(\"Minimum sequence length:\", min_seq_len)","metadata":{"execution":{"iopub.status.busy":"2023-11-04T06:08:19.559063Z","iopub.execute_input":"2023-11-04T06:08:19.559432Z","iopub.status.idle":"2023-11-04T06:08:20.190648Z","shell.execute_reply.started":"2023-11-04T06:08:19.559397Z","shell.execute_reply":"2023-11-04T06:08:20.189732Z"},"trusted":true},"execution_count":76,"outputs":[{"name":"stdout","text":"0       621\n1       734\n2       679\n3       749\n4       624\n       ... \n8880    227\n8881    229\n8882    194\n8883    243\n8884    186\nLength: 8885, dtype: int64\nMinimum sequence length: 125\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"# processed_data[0]","metadata":{"execution":{"iopub.status.busy":"2023-11-04T06:08:30.012116Z","iopub.execute_input":"2023-11-04T06:08:30.012999Z","iopub.status.idle":"2023-11-04T06:08:30.016785Z","shell.execute_reply.started":"2023-11-04T06:08:30.012962Z","shell.execute_reply":"2023-11-04T06:08:30.015839Z"},"trusted":true},"execution_count":77,"outputs":[]},{"cell_type":"code","source":"answer =[]\nstart =[]\nfor item in processed_data:\n    item['question'] = item.pop('claim')\n    if item['evidence'] is None:\n        item['answers'] = {\n            'answer_start': [],\n            'text': []      \n        }\n        item.pop('evidence')\n        continue\n\n    item['answers'] = {\n        'answer_start': [item.pop('evidence_start')],\n        'text': [item.pop('evidence')]      \n    }","metadata":{"execution":{"iopub.status.busy":"2023-11-04T06:08:31.933277Z","iopub.execute_input":"2023-11-04T06:08:31.933682Z","iopub.status.idle":"2023-11-04T06:08:31.960256Z","shell.execute_reply.started":"2023-11-04T06:08:31.933649Z","shell.execute_reply":"2023-11-04T06:08:31.959249Z"},"trusted":true},"execution_count":78,"outputs":[]},{"cell_type":"code","source":"with open('/kaggle/working/data-processed-9000.json','w') as file:\n    json.dump(processed_data,file)","metadata":{"execution":{"iopub.status.busy":"2023-11-04T06:08:41.799078Z","iopub.execute_input":"2023-11-04T06:08:41.799480Z","iopub.status.idle":"2023-11-04T06:08:42.291691Z","shell.execute_reply.started":"2023-11-04T06:08:41.799446Z","shell.execute_reply":"2023-11-04T06:08:42.290698Z"},"trusted":true},"execution_count":79,"outputs":[]},{"cell_type":"code","source":"with open('/kaggle/input/data-2-class-processed-24k/wrong2.json','r') as file:\n    processed = json.load(file)","metadata":{"execution":{"iopub.status.busy":"2023-11-01T06:08:09.156737Z","iopub.execute_input":"2023-11-01T06:08:09.157130Z","iopub.status.idle":"2023-11-01T06:08:09.251832Z","shell.execute_reply.started":"2023-11-01T06:08:09.157102Z","shell.execute_reply":"2023-11-01T06:08:09.251080Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"processed_data=[]\nfor i in processed:\n    processed_data.append(i[0])","metadata":{"execution":{"iopub.status.busy":"2023-11-01T06:08:09.955876Z","iopub.execute_input":"2023-11-01T06:08:09.956619Z","iopub.status.idle":"2023-11-01T06:08:09.961001Z","shell.execute_reply.started":"2023-11-01T06:08:09.956584Z","shell.execute_reply":"2023-11-01T06:08:09.960068Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"processed_data[0]","metadata":{"execution":{"iopub.status.busy":"2023-11-01T06:08:11.956234Z","iopub.execute_input":"2023-11-01T06:08:11.956557Z","iopub.status.idle":"2023-11-01T06:08:11.963601Z","shell.execute_reply.started":"2023-11-01T06:08:11.956534Z","shell.execute_reply":"2023-11-01T06:08:11.962664Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoTokenizer, XLMRobertaForQuestionAnswering\nfrom transformers import AutoModelForQuestionAnswering\n# from model.mrc_model import MRCQuestionAnswering\nfrom datasets import load_dataset, load_metric","metadata":{"execution":{"iopub.status.busy":"2023-11-04T06:08:55.521139Z","iopub.execute_input":"2023-11-04T06:08:55.521608Z","iopub.status.idle":"2023-11-04T06:08:55.532015Z","shell.execute_reply.started":"2023-11-04T06:08:55.521572Z","shell.execute_reply":"2023-11-04T06:08:55.531244Z"},"trusted":true},"execution_count":80,"outputs":[]},{"cell_type":"code","source":"squad_v2 = True","metadata":{"execution":{"iopub.status.busy":"2023-11-04T06:08:56.306070Z","iopub.execute_input":"2023-11-04T06:08:56.306766Z","iopub.status.idle":"2023-11-04T06:08:56.311104Z","shell.execute_reply.started":"2023-11-04T06:08:56.306728Z","shell.execute_reply":"2023-11-04T06:08:56.310087Z"},"trusted":true},"execution_count":81,"outputs":[]},{"cell_type":"code","source":"model_checkpoint = \"deepset/roberta-base-squad2\"\ntokenizer = AutoTokenizer.from_pretrained(model_checkpoint)","metadata":{"execution":{"iopub.status.busy":"2023-11-04T06:08:57.848185Z","iopub.execute_input":"2023-11-04T06:08:57.849044Z","iopub.status.idle":"2023-11-04T06:08:59.741502Z","shell.execute_reply.started":"2023-11-04T06:08:57.849003Z","shell.execute_reply":"2023-11-04T06:08:59.740489Z"},"trusted":true},"execution_count":82,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading (…)okenizer_config.json:   0%|          | 0.00/79.0 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"dcfc5025b00240ef8f9d5478cf49214a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)lve/main/config.json:   0%|          | 0.00/571 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"daf711cb4ec04153bbb913be21c40386"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)olve/main/vocab.json:   0%|          | 0.00/899k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7df16ec9962d4fc9bae5996b551eb841"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)olve/main/merges.txt:   0%|          | 0.00/456k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"8261c95da8834fe2965236a8e3e4052c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading (…)cial_tokens_map.json:   0%|          | 0.00/772 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ecdfcd05c21344b195ea2cb65f5db909"}},"metadata":{}}]},{"cell_type":"code","source":"tokenizer.is_fast","metadata":{"execution":{"iopub.status.busy":"2023-11-04T06:08:59.743163Z","iopub.execute_input":"2023-11-04T06:08:59.743485Z","iopub.status.idle":"2023-11-04T06:08:59.749646Z","shell.execute_reply.started":"2023-11-04T06:08:59.743458Z","shell.execute_reply":"2023-11-04T06:08:59.748651Z"},"trusted":true},"execution_count":83,"outputs":[{"execution_count":83,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}]},{"cell_type":"code","source":"test_data = processed_data","metadata":{"execution":{"iopub.status.busy":"2023-11-04T06:09:00.544846Z","iopub.execute_input":"2023-11-04T06:09:00.545780Z","iopub.status.idle":"2023-11-04T06:09:00.550979Z","shell.execute_reply.started":"2023-11-04T06:09:00.545728Z","shell.execute_reply":"2023-11-04T06:09:00.549798Z"},"trusted":true},"execution_count":84,"outputs":[]},{"cell_type":"code","source":"from sklearn.model_selection import train_test_split\n\n\n# Tách dữ liệu thành tập train và tập test\ntrain_data, val_data = train_test_split(processed_data, test_size=0.2, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2023-11-04T06:09:01.785254Z","iopub.execute_input":"2023-11-04T06:09:01.786167Z","iopub.status.idle":"2023-11-04T06:09:01.794949Z","shell.execute_reply.started":"2023-11-04T06:09:01.786132Z","shell.execute_reply":"2023-11-04T06:09:01.793896Z"},"trusted":true},"execution_count":85,"outputs":[]},{"cell_type":"code","source":"val_data, test_data = train_test_split(val_data, test_size=0.5, random_state=42)","metadata":{"execution":{"iopub.status.busy":"2023-11-04T06:09:02.227853Z","iopub.execute_input":"2023-11-04T06:09:02.228455Z","iopub.status.idle":"2023-11-04T06:09:02.234042Z","shell.execute_reply.started":"2023-11-04T06:09:02.228421Z","shell.execute_reply":"2023-11-04T06:09:02.233044Z"},"trusted":true},"execution_count":86,"outputs":[]},{"cell_type":"code","source":"train_data = pd.DataFrame(train_data)","metadata":{"execution":{"iopub.status.busy":"2023-11-04T06:09:03.099085Z","iopub.execute_input":"2023-11-04T06:09:03.099476Z","iopub.status.idle":"2023-11-04T06:09:03.119476Z","shell.execute_reply.started":"2023-11-04T06:09:03.099441Z","shell.execute_reply":"2023-11-04T06:09:03.118617Z"},"trusted":true},"execution_count":87,"outputs":[]},{"cell_type":"code","source":"train_data.head()","metadata":{"execution":{"iopub.status.busy":"2023-11-04T06:09:03.281148Z","iopub.execute_input":"2023-11-04T06:09:03.282146Z","iopub.status.idle":"2023-11-04T06:09:03.306231Z","shell.execute_reply.started":"2023-11-04T06:09:03.282115Z","shell.execute_reply":"2023-11-04T06:09:03.305555Z"},"trusted":true},"execution_count":88,"outputs":[{"execution_count":88,"output_type":"execute_result","data":{"text/plain":"                                             context    verdict     id  \\\n0  Điểm cuốn hút của món này là cá hồi tươi ngon ...    REFUTED  33581   \n1  Ngay cả việc tải tài liệu từ nhiều website mà ...    REFUTED  32349   \n2  Theo phát ngôn viên của Cơ quan Quản Lý Khí Qu...  SUPPORTED  35659   \n3  Chính sách hỗ trợ bao gồm cả khóa học trẻ em, ...        NEI    676   \n4  Bác sĩ khuyến cáo khi có dấu hiệu đau bụng, nô...    REFUTED  21606   \n\n                                            question  \\\n0  Điểm không cuốn hút của món gỏi cá hồi ngó sen...   \n1  việc tải tài liệu từ nhiều website mà chưa đượ...   \n2  Rice cho biết trung bình 6 trường hợp cá voi l...   \n3  Chính sách hỗ trợ bao gồm cả khóa học trẻ em, ...   \n4  Bác sĩ khuyến cáo khi có dấu hiệu đau bụng, nô...   \n\n                                             answers  \n0  {'answer_start': [0], 'text': ['Điểm cuốn hút ...  \n1  {'answer_start': [0], 'text': ['Ngay cả việc t...  \n2  {'answer_start': [839], 'text': ['\"Chúng tôi g...  \n3                   {'answer_start': [], 'text': []}  \n4  {'answer_start': [0], 'text': ['Bác sĩ khuyến ...  ","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>context</th>\n      <th>verdict</th>\n      <th>id</th>\n      <th>question</th>\n      <th>answers</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>Điểm cuốn hút của món này là cá hồi tươi ngon ...</td>\n      <td>REFUTED</td>\n      <td>33581</td>\n      <td>Điểm không cuốn hút của món gỏi cá hồi ngó sen...</td>\n      <td>{'answer_start': [0], 'text': ['Điểm cuốn hút ...</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>Ngay cả việc tải tài liệu từ nhiều website mà ...</td>\n      <td>REFUTED</td>\n      <td>32349</td>\n      <td>việc tải tài liệu từ nhiều website mà chưa đượ...</td>\n      <td>{'answer_start': [0], 'text': ['Ngay cả việc t...</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>Theo phát ngôn viên của Cơ quan Quản Lý Khí Qu...</td>\n      <td>SUPPORTED</td>\n      <td>35659</td>\n      <td>Rice cho biết trung bình 6 trường hợp cá voi l...</td>\n      <td>{'answer_start': [839], 'text': ['\"Chúng tôi g...</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>Chính sách hỗ trợ bao gồm cả khóa học trẻ em, ...</td>\n      <td>NEI</td>\n      <td>676</td>\n      <td>Chính sách hỗ trợ bao gồm cả khóa học trẻ em, ...</td>\n      <td>{'answer_start': [], 'text': []}</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>Bác sĩ khuyến cáo khi có dấu hiệu đau bụng, nô...</td>\n      <td>REFUTED</td>\n      <td>21606</td>\n      <td>Bác sĩ khuyến cáo khi có dấu hiệu đau bụng, nô...</td>\n      <td>{'answer_start': [0], 'text': ['Bác sĩ khuyến ...</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"train_data = Dataset.from_pandas(train_data)","metadata":{"execution":{"iopub.status.busy":"2023-11-04T06:09:03.838240Z","iopub.execute_input":"2023-11-04T06:09:03.839139Z","iopub.status.idle":"2023-11-04T06:09:04.013655Z","shell.execute_reply.started":"2023-11-04T06:09:03.839104Z","shell.execute_reply":"2023-11-04T06:09:04.012837Z"},"trusted":true},"execution_count":89,"outputs":[]},{"cell_type":"code","source":"train_data","metadata":{"execution":{"iopub.status.busy":"2023-11-04T06:09:04.412422Z","iopub.execute_input":"2023-11-04T06:09:04.412757Z","iopub.status.idle":"2023-11-04T06:09:04.418632Z","shell.execute_reply.started":"2023-11-04T06:09:04.412730Z","shell.execute_reply":"2023-11-04T06:09:04.417709Z"},"trusted":true},"execution_count":90,"outputs":[{"execution_count":90,"output_type":"execute_result","data":{"text/plain":"Dataset({\n    features: ['context', 'verdict', 'id', 'question', 'answers'],\n    num_rows: 7108\n})"},"metadata":{}}]},{"cell_type":"code","source":"val_data = pd.DataFrame(val_data)","metadata":{"execution":{"iopub.status.busy":"2023-11-04T06:09:04.846337Z","iopub.execute_input":"2023-11-04T06:09:04.846732Z","iopub.status.idle":"2023-11-04T06:09:04.854364Z","shell.execute_reply.started":"2023-11-04T06:09:04.846701Z","shell.execute_reply":"2023-11-04T06:09:04.853500Z"},"trusted":true},"execution_count":91,"outputs":[]},{"cell_type":"code","source":"val_data = Dataset.from_pandas(val_data)","metadata":{"execution":{"iopub.status.busy":"2023-11-04T06:09:05.376177Z","iopub.execute_input":"2023-11-04T06:09:05.376928Z","iopub.status.idle":"2023-11-04T06:09:05.404165Z","shell.execute_reply.started":"2023-11-04T06:09:05.376894Z","shell.execute_reply":"2023-11-04T06:09:05.403180Z"},"trusted":true},"execution_count":92,"outputs":[]},{"cell_type":"code","source":"test_data = pd.DataFrame(test_data)","metadata":{"execution":{"iopub.status.busy":"2023-11-04T06:09:05.763425Z","iopub.execute_input":"2023-11-04T06:09:05.763751Z","iopub.status.idle":"2023-11-04T06:09:05.770670Z","shell.execute_reply.started":"2023-11-04T06:09:05.763712Z","shell.execute_reply":"2023-11-04T06:09:05.769765Z"},"trusted":true},"execution_count":93,"outputs":[]},{"cell_type":"code","source":"test_data = Dataset.from_pandas(test_data)","metadata":{"execution":{"iopub.status.busy":"2023-11-04T06:09:06.524572Z","iopub.execute_input":"2023-11-04T06:09:06.524931Z","iopub.status.idle":"2023-11-04T06:09:06.554502Z","shell.execute_reply.started":"2023-11-04T06:09:06.524899Z","shell.execute_reply":"2023-11-04T06:09:06.553577Z"},"trusted":true},"execution_count":94,"outputs":[]},{"cell_type":"markdown","source":"## Processed Data train","metadata":{}},{"cell_type":"code","source":"max_length = 512 # The maximum length of a feature (question and context)\ndoc_stride = 30","metadata":{"execution":{"iopub.status.busy":"2023-11-04T06:09:54.037056Z","iopub.execute_input":"2023-11-04T06:09:54.037453Z","iopub.status.idle":"2023-11-04T06:09:54.042131Z","shell.execute_reply.started":"2023-11-04T06:09:54.037415Z","shell.execute_reply":"2023-11-04T06:09:54.041045Z"},"trusted":true},"execution_count":99,"outputs":[]},{"cell_type":"code","source":"pad_on_right = tokenizer.padding_side == \"right\"","metadata":{"execution":{"iopub.status.busy":"2023-11-04T06:09:08.870602Z","iopub.execute_input":"2023-11-04T06:09:08.870959Z","iopub.status.idle":"2023-11-04T06:09:08.875346Z","shell.execute_reply.started":"2023-11-04T06:09:08.870931Z","shell.execute_reply":"2023-11-04T06:09:08.874364Z"},"trusted":true},"execution_count":96,"outputs":[]},{"cell_type":"code","source":"def prepare_train_features(examples):\n    # Some of the questions have lots of whitespace on the left, which is not useful and will make the\n    # truncation of the context fail (the tokenized question will take a lots of space). So we remove that\n    # left whitespace\n    examples[\"question\"] = [q.lstrip() for q in examples[\"question\"]]\n\n    # Tokenize our examples with truncation and padding, but keep the overflows using a stride. This results\n    # in one example possible giving several features when a context is long, each of those features having a\n    # context that overlaps a bit the context of the previous feature.\n    tokenized_examples = tokenizer(\n        examples[\"question\" if pad_on_right else \"context\"],\n        examples[\"context\" if pad_on_right else \"question\"],\n        truncation=\"only_second\" if pad_on_right else \"only_first\",\n        max_length=max_length,\n        stride=doc_stride,\n        return_overflowing_tokens=True,\n        return_offsets_mapping=True,\n        padding=\"max_length\",\n    )\n\n    # Since one example might give us several features if it has a long context, we need a map from a feature to\n    # its corresponding example. This key gives us just that.\n    sample_mapping = tokenized_examples.pop(\"overflow_to_sample_mapping\")\n    # The offset mappings will give us a map from token to character position in the original context. This will\n    # help us compute the start_positions and end_positions.\n    offset_mapping = tokenized_examples.pop(\"offset_mapping\")\n\n    # Let's label those examples!\n    tokenized_examples[\"start_positions\"] = []\n    tokenized_examples[\"end_positions\"] = []\n\n    for i, offsets in enumerate(offset_mapping):\n        # We will label impossible answers with the index of the CLS token.\n        input_ids = tokenized_examples[\"input_ids\"][i]\n        cls_index = input_ids.index(tokenizer.cls_token_id)\n\n        # Grab the sequence corresponding to that example (to know what is the context and what is the question).\n        sequence_ids = tokenized_examples.sequence_ids(i)\n\n        # One example can give several spans, this is the index of the example containing this span of text.\n        sample_index = sample_mapping[i]\n        answers = examples[\"answers\"][sample_index]\n        # If no answers are given, set the cls_index as answer.\n        if len(answers[\"answer_start\"]) == 0:\n            tokenized_examples[\"start_positions\"].append(cls_index)\n            tokenized_examples[\"end_positions\"].append(cls_index)\n        else:\n            # Start/end character index of the answer in the text.\n            start_char = answers[\"answer_start\"][0]\n            end_char = start_char + len(answers[\"text\"][0])\n\n            # Start token index of the current span in the text.\n            token_start_index = 0\n            while sequence_ids[token_start_index] != (1 if pad_on_right else 0):\n                token_start_index += 1\n\n            # End token index of the current span in the text.\n            token_end_index = len(input_ids) - 1\n            while sequence_ids[token_end_index] != (1 if pad_on_right else 0):\n                token_end_index -= 1\n\n            # Detect if the answer is out of the span (in which case this feature is labeled with the CLS index).\n            if not (offsets[token_start_index][0] <= start_char and offsets[token_end_index][1] >= end_char):\n                tokenized_examples[\"start_positions\"].append(cls_index)\n                tokenized_examples[\"end_positions\"].append(cls_index)\n            else:\n                # Otherwise move the token_start_index and token_end_index to the two ends of the answer.\n                # Note: we could go after the last offset if the answer is the last word (edge case).\n                while token_start_index < len(offsets) and offsets[token_start_index][0] <= start_char:\n                    token_start_index += 1\n                tokenized_examples[\"start_positions\"].append(token_start_index - 1)\n                while offsets[token_end_index][1] >= end_char:\n                    token_end_index -= 1\n                tokenized_examples[\"end_positions\"].append(token_end_index + 1)\n\n    return tokenized_examples","metadata":{"execution":{"iopub.status.busy":"2023-11-04T06:09:55.670105Z","iopub.execute_input":"2023-11-04T06:09:55.670600Z","iopub.status.idle":"2023-11-04T06:09:55.689691Z","shell.execute_reply.started":"2023-11-04T06:09:55.670556Z","shell.execute_reply":"2023-11-04T06:09:55.688645Z"},"trusted":true},"execution_count":100,"outputs":[]},{"cell_type":"code","source":"train_dataset = train_data.map(\n    prepare_train_features,\n    batched=True,\n    remove_columns=train_data.column_names,\n)\nlen(train_data), len(train_dataset)","metadata":{"execution":{"iopub.status.busy":"2023-11-04T06:09:55.812203Z","iopub.execute_input":"2023-11-04T06:09:55.812844Z","iopub.status.idle":"2023-11-04T06:10:25.011346Z","shell.execute_reply.started":"2023-11-04T06:09:55.812805Z","shell.execute_reply":"2023-11-04T06:10:25.010406Z"},"trusted":true},"execution_count":101,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/8 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c0881d67747648e9b6ba4cfebf27f2e2"}},"metadata":{}},{"execution_count":101,"output_type":"execute_result","data":{"text/plain":"(7108, 45778)"},"metadata":{}}]},{"cell_type":"code","source":"validation_dataset = val_data.map(\n    prepare_train_features,\n    batched=True,\n    remove_columns=val_data.column_names,\n)\nlen(val_data), len(validation_dataset)","metadata":{"execution":{"iopub.status.busy":"2023-11-04T06:10:27.158140Z","iopub.execute_input":"2023-11-04T06:10:27.158993Z","iopub.status.idle":"2023-11-04T06:10:30.837750Z","shell.execute_reply.started":"2023-11-04T06:10:27.158955Z","shell.execute_reply":"2023-11-04T06:10:30.836913Z"},"trusted":true},"execution_count":102,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"aa0c4752051043a39d8095cb40c26cd7"}},"metadata":{}},{"execution_count":102,"output_type":"execute_result","data":{"text/plain":"(888, 5760)"},"metadata":{}}]},{"cell_type":"markdown","source":"## Trainer API","metadata":{}},{"cell_type":"code","source":"!pip install evaluate","metadata":{"execution":{"iopub.status.busy":"2023-11-01T06:09:25.649383Z","iopub.execute_input":"2023-11-01T06:09:25.649726Z","iopub.status.idle":"2023-11-01T06:09:38.454595Z","shell.execute_reply.started":"2023-11-01T06:09:25.649700Z","shell.execute_reply":"2023-11-01T06:09:38.453480Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"model = XLMRobertaForQuestionAnswering.from_pretrained(model_checkpoint)","metadata":{"execution":{"iopub.status.busy":"2023-11-04T06:10:42.266182Z","iopub.execute_input":"2023-11-04T06:10:42.266906Z","iopub.status.idle":"2023-11-04T06:10:45.166245Z","shell.execute_reply.started":"2023-11-04T06:10:42.266867Z","shell.execute_reply":"2023-11-04T06:10:45.165430Z"},"trusted":true},"execution_count":103,"outputs":[{"name":"stderr","text":"You are using a model of type roberta to instantiate a model of type xlm-roberta. This is not supported for all configurations of models and can yield errors.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Downloading model.safetensors:   0%|          | 0.00/496M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"26a34ee4ea0540dd8ebe289e553e2f3a"}},"metadata":{}}]},{"cell_type":"code","source":"from transformers import TrainingArguments\n\nargs = TrainingArguments(\n    \"XLM-processed-squadv2\",\n    evaluation_strategy=\"epoch\",\n    save_strategy=\"no\",\n    learning_rate=2e-5,\n    num_train_epochs=2,\n    weight_decay=0.01,\n    per_device_train_batch_size=4,\n    per_device_eval_batch_size=4,\n    fp16=True,\n#     save_strategy ='no',\n    push_to_hub=True,\n)","metadata":{"execution":{"iopub.status.busy":"2023-11-04T06:10:50.279837Z","iopub.execute_input":"2023-11-04T06:10:50.280520Z","iopub.status.idle":"2023-11-04T06:10:50.289120Z","shell.execute_reply.started":"2023-11-04T06:10:50.280484Z","shell.execute_reply":"2023-11-04T06:10:50.288251Z"},"trusted":true},"execution_count":104,"outputs":[]},{"cell_type":"code","source":"from transformers import Trainer\n\ntrainer = Trainer(\n    model=model,\n    args=args,\n    train_dataset=train_dataset,\n    eval_dataset=validation_dataset,\n    tokenizer=tokenizer,\n)\ntrainer.train()","metadata":{"execution":{"iopub.status.busy":"2023-11-04T06:10:52.809212Z","iopub.execute_input":"2023-11-04T06:10:52.809612Z","iopub.status.idle":"2023-11-04T07:53:49.723468Z","shell.execute_reply.started":"2023-11-04T06:10:52.809576Z","shell.execute_reply":"2023-11-04T07:53:49.722500Z"},"trusted":true},"execution_count":105,"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Logging into wandb.ai. (Learn how to deploy a W&B server locally: https://wandb.me/wandb-server)\n\u001b[34m\u001b[1mwandb\u001b[0m: You can find your API key in your browser here: https://wandb.ai/authorize\n\u001b[34m\u001b[1mwandb\u001b[0m: Paste an API key from your profile and hit enter, or press ctrl+c to quit:","output_type":"stream"},{"output_type":"stream","name":"stdin","text":"  ········································\n"},{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"wandb version 0.15.12 is available!  To upgrade, please run:\n $ pip install wandb --upgrade"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.15.9"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20231104_061128-x5auowx1</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/huutri231103/huggingface/runs/x5auowx1' target=\"_blank\">zany-paper-50</a></strong> to <a href='https://wandb.ai/huutri231103/huggingface' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/run' target=\"_blank\">docs</a>)<br/>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/huutri231103/huggingface' target=\"_blank\">https://wandb.ai/huutri231103/huggingface</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/huutri231103/huggingface/runs/x5auowx1' target=\"_blank\">https://wandb.ai/huutri231103/huggingface/runs/x5auowx1</a>"},"metadata":{}},{"name":"stderr","text":"You're using a RobertaTokenizerFast tokenizer. Please note that with a fast tokenizer, using the `__call__` method is faster than using a method to encode the text followed by a call to the `pad` method to get a padded encoding.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"\n    <div>\n      \n      <progress value='22890' max='22890' style='width:300px; height:20px; vertical-align: middle;'></progress>\n      [22890/22890 1:41:49, Epoch 2/2]\n    </div>\n    <table border=\"1\" class=\"dataframe\">\n  <thead>\n <tr style=\"text-align: left;\">\n      <th>Epoch</th>\n      <th>Training Loss</th>\n      <th>Validation Loss</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <td>1</td>\n      <td>0.217300</td>\n      <td>0.229198</td>\n    </tr>\n    <tr>\n      <td>2</td>\n      <td>0.194600</td>\n      <td>0.238271</td>\n    </tr>\n  </tbody>\n</table><p>"},"metadata":{}},{"text":"IOPub message rate exceeded.\nThe notebook server will temporarily stop sending output\nto the client in order to avoid crashing it.\nTo change this limit, set the config variable\n`--NotebookApp.iopub_msg_rate_limit`.\n\nCurrent values:\nNotebookApp.iopub_msg_rate_limit=1000.0 (msgs/sec)\nNotebookApp.rate_limit_window=3.0 (secs)\n\n","name":"stderr","output_type":"stream"},{"execution_count":105,"output_type":"execute_result","data":{"text/plain":"TrainOutput(global_step=22890, training_loss=0.2610287320931544, metrics={'train_runtime': 6176.0542, 'train_samples_per_second': 14.824, 'train_steps_per_second': 3.706, 'total_flos': 2.3923285859721216e+16, 'train_loss': 0.2610287320931544, 'epoch': 2.0})"},"metadata":{}}]},{"cell_type":"code","source":"trainer.save_model('XLM-processed-squadv2')","metadata":{"execution":{"iopub.status.busy":"2023-11-04T07:54:08.288771Z","iopub.execute_input":"2023-11-04T07:54:08.289133Z","iopub.status.idle":"2023-11-04T07:54:32.659897Z","shell.execute_reply.started":"2023-11-04T07:54:08.289099Z","shell.execute_reply":"2023-11-04T07:54:32.658796Z"},"trusted":true},"execution_count":106,"outputs":[{"output_type":"display_data","data":{"text/plain":"training_args.bin:   0%|          | 0.00/4.09k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c8055be5f57c4418af151f6a7cf4e397"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"pytorch_model.bin:   0%|          | 0.00/496M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"4d29ab242b534f58a3139c45a2e4c298"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Upload 2 LFS files:   0%|          | 0/2 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"ac7bb400095d4550a6cda6c13b3fc033"}},"metadata":{}}]},{"cell_type":"code","source":"trainer.push_to_hub(commit_message=\"Training complete\")","metadata":{"execution":{"iopub.status.busy":"2023-11-04T07:54:32.662266Z","iopub.execute_input":"2023-11-04T07:54:32.662701Z","iopub.status.idle":"2023-11-04T07:54:36.269616Z","shell.execute_reply.started":"2023-11-04T07:54:32.662660Z","shell.execute_reply":"2023-11-04T07:54:36.268593Z"},"trusted":true},"execution_count":107,"outputs":[{"execution_count":107,"output_type":"execute_result","data":{"text/plain":"'https://huggingface.co/FuuToru/XLM-processed-squadv2/tree/main/'"},"metadata":{}}]},{"cell_type":"code","source":"stride=40","metadata":{"execution":{"iopub.status.busy":"2023-11-04T07:54:36.270801Z","iopub.execute_input":"2023-11-04T07:54:36.271105Z","iopub.status.idle":"2023-11-04T07:54:36.276300Z","shell.execute_reply.started":"2023-11-04T07:54:36.271078Z","shell.execute_reply":"2023-11-04T07:54:36.275122Z"},"trusted":true},"execution_count":108,"outputs":[]},{"cell_type":"code","source":"def prepare_validation_features(examples):\n    # Some of the questions have lots of whitespace on the left, which is not useful and will make the\n    # truncation of the context fail (the tokenized question will take a lots of space). So we remove that\n    # left whitespace\n    examples[\"question\"] = [q.lstrip() for q in examples[\"question\"]]\n\n    # Tokenize our examples with truncation and maybe padding, but keep the overflows using a stride. This results\n    # in one example possible giving several features when a context is long, each of those features having a\n    # context that overlaps a bit the context of the previous feature.\n    tokenized_examples = tokenizer(\n        examples[\"question\" if pad_on_right else \"context\"],\n        examples[\"context\" if pad_on_right else \"question\"],\n        truncation=\"only_second\" if pad_on_right else \"only_first\",\n        max_length=max_length,\n        stride=doc_stride,\n        return_overflowing_tokens=True,\n        return_offsets_mapping=True,\n        padding=\"max_length\",\n    )\n\n    # Since one example might give us several features if it has a long context, we need a map from a feature to\n    # its corresponding example. This key gives us just that.\n    sample_mapping = tokenized_examples.pop(\"overflow_to_sample_mapping\")\n\n    # We keep the example_id that gave us this feature and we will store the offset mappings.\n    tokenized_examples[\"example_id\"] = []\n\n    for i in range(len(tokenized_examples[\"input_ids\"])):\n        # Grab the sequence corresponding to that example (to know what is the context and what is the question).\n        sequence_ids = tokenized_examples.sequence_ids(i)\n        context_index = 1 if pad_on_right else 0\n\n        # One example can give several spans, this is the index of the example containing this span of text.\n        sample_index = sample_mapping[i]\n        tokenized_examples[\"example_id\"].append(examples[\"id\"][sample_index])\n\n        # Set to None the offset_mapping that are not part of the context so it's easy to determine if a token\n        # position is part of the context or not.\n        tokenized_examples[\"offset_mapping\"][i] = [\n            (o if sequence_ids[k] == context_index else None)\n            for k, o in enumerate(tokenized_examples[\"offset_mapping\"][i])\n        ]\n\n    return tokenized_examples","metadata":{"execution":{"iopub.status.busy":"2023-11-04T07:54:36.278651Z","iopub.execute_input":"2023-11-04T07:54:36.278990Z","iopub.status.idle":"2023-11-04T07:54:36.902040Z","shell.execute_reply.started":"2023-11-04T07:54:36.278958Z","shell.execute_reply":"2023-11-04T07:54:36.900972Z"},"trusted":true},"execution_count":109,"outputs":[]},{"cell_type":"code","source":"test_dataset = test_data.map(\n    prepare_validation_features,\n    batched=True,\n    remove_columns=test_data.column_names,\n)\nlen(test_data), len(test_dataset)","metadata":{"execution":{"iopub.status.busy":"2023-11-04T07:54:36.903425Z","iopub.execute_input":"2023-11-04T07:54:36.904215Z","iopub.status.idle":"2023-11-04T07:55:44.954669Z","shell.execute_reply.started":"2023-11-04T07:54:36.904178Z","shell.execute_reply":"2023-11-04T07:55:44.953626Z"},"trusted":true},"execution_count":110,"outputs":[{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/1 [00:00<?, ?ba/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b76d9f9a5e6c41afbb190b2294fa72bd"}},"metadata":{}},{"execution_count":110,"output_type":"execute_result","data":{"text/plain":"(889, 5527)"},"metadata":{}}]},{"cell_type":"code","source":"raw_predictions = trainer.predict(test_dataset)","metadata":{"execution":{"iopub.status.busy":"2023-11-04T07:56:11.488861Z","iopub.execute_input":"2023-11-04T07:56:11.489609Z","iopub.status.idle":"2023-11-04T07:58:05.444226Z","shell.execute_reply.started":"2023-11-04T07:56:11.489575Z","shell.execute_reply":"2023-11-04T07:58:05.443178Z"},"trusted":true},"execution_count":111,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":""},"metadata":{}}]},{"cell_type":"code","source":"# trained_checkpoint = \"FuuToru/XLM-processed-squadv2\"\n# tokenizer = AutoTokenizer.from_pretrained(trained_checkpoint)\n# trained_model = XLMRobertaForQuestionAnswering.from_pretrained(trained_checkpoint)","metadata":{"execution":{"iopub.status.busy":"2023-11-04T07:58:44.156815Z","iopub.execute_input":"2023-11-04T07:58:44.157183Z","iopub.status.idle":"2023-11-04T07:58:44.162829Z","shell.execute_reply.started":"2023-11-04T07:58:44.157152Z","shell.execute_reply":"2023-11-04T07:58:44.161932Z"},"trusted":true},"execution_count":112,"outputs":[]},{"cell_type":"code","source":"from tqdm.auto import tqdm\nimport collections\n\ndef postprocess_qa_predictions(examples, features, raw_predictions, n_best_size = 20, max_answer_length = 400):\n    all_start_logits, all_end_logits = raw_predictions\n    # Build a map example to its corresponding features.\n    example_id_to_index = {k: i for i, k in enumerate(examples[\"id\"])}\n    features_per_example = collections.defaultdict(list)\n    for i, feature in enumerate(features):\n        features_per_example[example_id_to_index[feature[\"example_id\"]]].append(i)\n\n    # The dictionaries we have to fill.\n    predictions = collections.OrderedDict()\n\n    # Logging.\n    print(f\"Post-processing {len(examples)} example predictions split into {len(features)} features.\")\n\n    # Let's loop over all the examples!\n    for example_index, example in enumerate(tqdm(examples)):\n        # Those are the indices of the features associated to the current example.\n        feature_indices = features_per_example[example_index]\n\n        min_null_score = None # Only used if squad_v2 is True.\n        valid_answers = []\n        \n        context = example[\"context\"]\n        # Looping through all the features associated to the current example.\n        for feature_index in feature_indices:\n            # We grab the predictions of the model for this feature.\n            start_logits = all_start_logits[feature_index]\n            end_logits = all_end_logits[feature_index]\n            # This is what will allow us to map some the positions in our logits to span of texts in the original\n            # context.\n            offset_mapping = features[feature_index][\"offset_mapping\"]\n\n            # Update minimum null prediction.\n            cls_index = features[feature_index][\"input_ids\"].index(tokenizer.cls_token_id)\n            feature_null_score = start_logits[cls_index] + end_logits[cls_index]\n            if min_null_score is None or min_null_score < feature_null_score:\n                min_null_score = feature_null_score\n\n            # Go through all possibilities for the `n_best_size` greater start and end logits.\n            start_indexes = np.argsort(start_logits)[-1 : -n_best_size - 1 : -1].tolist()\n            end_indexes = np.argsort(end_logits)[-1 : -n_best_size - 1 : -1].tolist()\n            for start_index in start_indexes:\n                for end_index in end_indexes:\n                    # Don't consider out-of-scope answers, either because the indices are out of bounds or correspond\n                    # to part of the input_ids that are not in the context.\n                    if (\n                        start_index >= len(offset_mapping)\n                        or end_index >= len(offset_mapping)\n                        or offset_mapping[start_index] is None\n                        or offset_mapping[end_index] is None\n                    ):\n                        continue\n                    # Don't consider answers with a length that is either < 0 or > max_answer_length.\n                    if end_index < start_index or end_index - start_index + 1 > max_answer_length:\n                        continue\n\n                    start_char = offset_mapping[start_index][0]\n                    end_char = offset_mapping[end_index][1]\n                    valid_answers.append(\n                        {\n                            \"score\": start_logits[start_index] + end_logits[end_index],\n                            \"text\": context[start_char: end_char]\n                        }\n                    )\n        \n        if len(valid_answers) > 0:\n            best_answer = sorted(valid_answers, key=lambda x: x[\"score\"], reverse=True)[0]\n        else:\n            # In the very rare edge case we have not a single non-null prediction, we create a fake prediction to avoid\n            # failure.\n            best_answer = {\"text\": \"\", \"score\": 0.0}\n        \n        # Let's pick our final answer: the best one or the null answer (only for squad_v2)\n        if not squad_v2:\n            predictions[example[\"id\"]] = best_answer[\"text\"]\n        else:\n            answer = best_answer[\"text\"] if best_answer[\"score\"] > min_null_score else \"\"\n            predictions[example[\"id\"]] = answer\n\n    return predictions","metadata":{"execution":{"iopub.status.busy":"2023-11-04T07:58:44.579794Z","iopub.execute_input":"2023-11-04T07:58:44.580461Z","iopub.status.idle":"2023-11-04T07:58:44.599783Z","shell.execute_reply.started":"2023-11-04T07:58:44.580425Z","shell.execute_reply":"2023-11-04T07:58:44.597917Z"},"trusted":true},"execution_count":113,"outputs":[]},{"cell_type":"code","source":"final_predictions = postprocess_qa_predictions(test_data, test_dataset, raw_predictions.predictions)","metadata":{"execution":{"iopub.status.busy":"2023-11-04T07:58:50.015887Z","iopub.execute_input":"2023-11-04T07:58:50.016244Z","iopub.status.idle":"2023-11-04T07:59:35.350902Z","shell.execute_reply.started":"2023-11-04T07:58:50.016209Z","shell.execute_reply":"2023-11-04T07:59:35.349742Z"},"trusted":true},"execution_count":114,"outputs":[{"name":"stdout","text":"Post-processing 889 example predictions split into 5527 features.\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"  0%|          | 0/889 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c391a0883e55484aa70854a4f5c01cf8"}},"metadata":{}}]},{"cell_type":"code","source":"metric = load_metric(\"squad_v2\" if squad_v2 else \"squad\")","metadata":{"execution":{"iopub.status.busy":"2023-11-04T07:59:38.025157Z","iopub.execute_input":"2023-11-04T07:59:38.025526Z","iopub.status.idle":"2023-11-04T07:59:38.899863Z","shell.execute_reply.started":"2023-11-04T07:59:38.025495Z","shell.execute_reply":"2023-11-04T07:59:38.898861Z"},"trusted":true},"execution_count":115,"outputs":[{"output_type":"display_data","data":{"text/plain":"Downloading builder script:   0%|          | 0.00/2.25k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"599dac5ef88f4c4b88d4365246ad01d1"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"Downloading extra modules:   0%|          | 0.00/3.19k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"7e305bf1da9146b78a69d84fcb461ebb"}},"metadata":{}}]},{"cell_type":"code","source":"if squad_v2:\n    formatted_predictions = [{\"id\": k, \"prediction_text\": v, \"no_answer_probability\": 0.0} for k, v in final_predictions.items()]\nelse:\n    formatted_predictions = [{\"id\": k, \"prediction_text\": v} for k, v in final_predictions.items()]\nreferences = [{\"id\": ex[\"id\"], \"answers\": ex[\"answers\"]} for ex in test_data]\n","metadata":{"execution":{"iopub.status.busy":"2023-11-04T07:59:38.901339Z","iopub.execute_input":"2023-11-04T07:59:38.901650Z","iopub.status.idle":"2023-11-04T07:59:39.022412Z","shell.execute_reply.started":"2023-11-04T07:59:38.901623Z","shell.execute_reply":"2023-11-04T07:59:39.021447Z"},"trusted":true},"execution_count":116,"outputs":[]},{"cell_type":"code","source":"# formatted_predictions","metadata":{"execution":{"iopub.status.busy":"2023-11-04T08:03:57.457183Z","iopub.execute_input":"2023-11-04T08:03:57.457933Z","iopub.status.idle":"2023-11-04T08:03:57.463994Z","shell.execute_reply.started":"2023-11-04T08:03:57.457894Z","shell.execute_reply":"2023-11-04T08:03:57.462445Z"},"trusted":true},"execution_count":119,"outputs":[]},{"cell_type":"code","source":"metric.compute(predictions=formatted_predictions, references=references)","metadata":{"execution":{"iopub.status.busy":"2023-11-04T07:59:41.406474Z","iopub.execute_input":"2023-11-04T07:59:41.407188Z","iopub.status.idle":"2023-11-04T07:59:41.577434Z","shell.execute_reply.started":"2023-11-04T07:59:41.407152Z","shell.execute_reply":"2023-11-04T07:59:41.576451Z"},"trusted":true},"execution_count":117,"outputs":[{"execution_count":117,"output_type":"execute_result","data":{"text/plain":"{'exact': 38.47019122609674,\n 'f1': 38.49268841394826,\n 'total': 889,\n 'HasAns_exact': 7.75716694772344,\n 'HasAns_f1': 7.790893760539629,\n 'HasAns_total': 593,\n 'NoAns_exact': 100.0,\n 'NoAns_f1': 100.0,\n 'NoAns_total': 296,\n 'best_exact': 38.47019122609674,\n 'best_exact_thresh': 0.0,\n 'best_f1': 38.49268841394826,\n 'best_f1_thresh': 0.0}"},"metadata":{}}]},{"cell_type":"code","source":"import torch\nfrom transformers import AutoModelForQuestionAnswering\nfrom tqdm.auto import tqdm\n\ntest_set_for_model = test_dataset.remove_columns([\"example_id\", \"offset_mapping\"])\ntest_set_for_model.set_format(\"torch\")\n\ndevice = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\ntrained_model = XLMRobertaForQuestionAnswering.from_pretrained(trained_checkpoint).to(\n    device\n)\n\nbatch_size = 4  # Hoặc giảm còn ít hơn\n\n# Chia dữ liệu thành các batch nhỏ hơn\ntotal_samples = len(test_set_for_model[\"input_ids\"])\noutputs = []  # Để tích lũy kết quả từ từng batch\nfor start in tqdm(range(0, total_samples, batch_size)):\n    end = min(start + batch_size, total_samples)\n    batch = {k: test_set_for_model[k][start:end].to(device) for k in test_set_for_model.column_names}\n    with torch.no_grad():\n        output = trained_model(**batch)\n    outputs.append(output)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-01T06:11:28.461370Z","iopub.execute_input":"2023-11-01T06:11:28.461755Z","iopub.status.idle":"2023-11-01T06:14:02.707875Z","shell.execute_reply.started":"2023-11-01T06:11:28.461722Z","shell.execute_reply":"2023-11-01T06:14:02.706889Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport numpy as np\n\nstart_logits = torch.cat([output.start_logits for output in outputs], dim=0).cpu().numpy()\nend_logits = torch.cat([output.end_logits for output in outputs], dim=0).cpu().numpy()","metadata":{"execution":{"iopub.status.busy":"2023-11-01T06:14:02.709343Z","iopub.execute_input":"2023-11-01T06:14:02.709991Z","iopub.status.idle":"2023-11-01T06:14:02.723194Z","shell.execute_reply.started":"2023-11-01T06:14:02.709954Z","shell.execute_reply":"2023-11-01T06:14:02.722386Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm.auto import tqdm\nimport collections\n\n\ndef compute_metrics(start_logits, end_logits, features, examples):\n    example_to_features = collections.defaultdict(list)\n    for idx, feature in enumerate(features):\n        example_to_features[feature[\"example_id\"]].append(idx)\n    n_best = 20\n    max_answer_length = 400\n    predicted_answers = []\n    for example in tqdm(examples):\n        example_id = example[\"id\"]\n        context = example[\"context\"]\n        sentences = extract_sentences_offcial(context) \n        answers = []\n\n        # Lặp qua tất cả các đặc trưng liên quan tới mẫu đó\n        for feature_index in example_to_features[example_id]:\n            start_logit = start_logits[feature_index]\n            end_logit = end_logits[feature_index]\n            offsets = features[feature_index][\"offset_mapping\"]\n\n            start_indexes = np.argsort(start_logit)[-1 : -n_best - 1 : -1].tolist()\n            end_indexes = np.argsort(end_logit)[-1 : -n_best - 1 : -1].tolist()\n            for start_index in start_indexes:\n                for end_index in end_indexes:\n                    # Bỏ qua câu trả lời không xuất hiện hoàn toàn trong ngữ cảnh\n                    if  (start_index >= len(offsets)\n                        or end_index >= len(offsets)\n                        or offsets[start_index] is None \n                        or offsets[end_index] is None):\n                        continue\n                    # Bỏ qua những câu trả lời với độ dài < 0 hoặc > max_answer_length\n                    if len(offsets[start_index]) == 0 or len(offsets[end_index]) == 0:\n                        continue\n                    if (\n                        end_index <= start_index\n                        or end_index - start_index + 1 > max_answer_length\n                    ):\n                        continue\n\n                    answer = {\n                        \"text\": context[offsets[start_index][0] : offsets[end_index][1]],\n                        \"logit_score\": start_logit[start_index] + end_logit[end_index],\n                    }\n                    answers.append(answer)\n\n        # Chọn câu trả lời có điểm cao nhất\n        if len(answers) > 0:\n            best_answer = max(answers, key=lambda x: x[\"logit_score\"])                \n            predicted_answers.append(\n                {\"id\": example_id,\"context\": context,\"claim\": example['question'], \"evidence\": best_answer['text']}\n            )\n        else:\n            predicted_answers.append({\"id\": example_id,\"context\": context,\"claim\": example['question'], \"evidence\": sentences[0]})\n\n    return predicted_answers\n#     theoretical_answers = [{\"id\": ex[\"id\"], \"answers\": ex[\"answers\"]} for ex in examples]\n#     return metric.compute(predictions=predicted_answers, references=theoretical_answers)","metadata":{"execution":{"iopub.status.busy":"2023-11-01T06:14:02.725378Z","iopub.execute_input":"2023-11-01T06:14:02.725947Z","iopub.status.idle":"2023-11-01T06:14:02.738724Z","shell.execute_reply.started":"2023-11-01T06:14:02.725911Z","shell.execute_reply":"2023-11-01T06:14:02.737862Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predict = compute_metrics(start_logits, end_logits, test_dataset, test_data)","metadata":{"execution":{"iopub.status.busy":"2023-11-01T06:14:02.739892Z","iopub.execute_input":"2023-11-01T06:14:02.740184Z","iopub.status.idle":"2023-11-01T06:14:32.067501Z","shell.execute_reply.started":"2023-11-01T06:14:02.740127Z","shell.execute_reply":"2023-11-01T06:14:32.066510Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(predict)","metadata":{"execution":{"iopub.status.busy":"2023-11-01T06:16:14.548909Z","iopub.execute_input":"2023-11-01T06:16:14.549610Z","iopub.status.idle":"2023-11-01T06:16:14.555757Z","shell.execute_reply.started":"2023-11-01T06:16:14.549577Z","shell.execute_reply":"2023-11-01T06:16:14.554817Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for item in predict:\n    context = item['context']\n    sentences = extract_sentences_offcial(context)  \n    answer = item['evidence']\n    sentences_answers = extract_sentences_offcial(answer) \n    for sent in sentences:\n        if sentences_answers[0] in sent or sent in sentences_answers[0]:\n            item['evidence'] = sent\n            break\n    ","metadata":{"execution":{"iopub.status.busy":"2023-11-01T06:16:16.959822Z","iopub.execute_input":"2023-11-01T06:16:16.960571Z","iopub.status.idle":"2023-11-01T06:16:17.157028Z","shell.execute_reply.started":"2023-11-01T06:16:16.960525Z","shell.execute_reply":"2023-11-01T06:16:17.156014Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predict_answer =[\n    {\"id\":ex['id'],\"prediction_text\":ex['evidence']} for ex in predict\n]","metadata":{"execution":{"iopub.status.busy":"2023-11-01T06:16:17.178774Z","iopub.execute_input":"2023-11-01T06:16:17.179122Z","iopub.status.idle":"2023-11-01T06:16:17.185910Z","shell.execute_reply.started":"2023-11-01T06:16:17.179096Z","shell.execute_reply":"2023-11-01T06:16:17.184880Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"theoretical_answers = [\n    {\"id\": ex[\"id\"], \"answers\": ex[\"answers\"]} for ex in test_data\n]","metadata":{"execution":{"iopub.status.busy":"2023-11-01T06:16:18.513184Z","iopub.execute_input":"2023-11-01T06:16:18.513542Z","iopub.status.idle":"2023-11-01T06:16:18.649306Z","shell.execute_reply.started":"2023-11-01T06:16:18.513514Z","shell.execute_reply":"2023-11-01T06:16:18.648288Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import evaluate\n\nmetric = evaluate.load(\"squad\")","metadata":{"execution":{"iopub.status.busy":"2023-11-01T06:16:19.760792Z","iopub.execute_input":"2023-11-01T06:16:19.761710Z","iopub.status.idle":"2023-11-01T06:16:24.337598Z","shell.execute_reply.started":"2023-11-01T06:16:19.761678Z","shell.execute_reply":"2023-11-01T06:16:24.336643Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"metric.compute(predictions=predict_answer, references=theoretical_answers)","metadata":{"execution":{"iopub.status.busy":"2023-11-01T06:16:24.339156Z","iopub.execute_input":"2023-11-01T06:16:24.339443Z","iopub.status.idle":"2023-11-01T06:16:24.559126Z","shell.execute_reply.started":"2023-11-01T06:16:24.339418Z","shell.execute_reply":"2023-11-01T06:16:24.558209Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# for item in range(len(theoretical_answers)): \n#     print(\"Predict: \",predict[item])\n#     print(\"Theoretical: \",theoretical_answers[item])\n#     print(\"\\n------------------------------------------\\n\")","metadata":{"execution":{"iopub.status.busy":"2023-11-01T06:33:16.082325Z","iopub.execute_input":"2023-11-01T06:33:16.083086Z","iopub.status.idle":"2023-11-01T06:33:16.087116Z","shell.execute_reply.started":"2023-11-01T06:33:16.083052Z","shell.execute_reply":"2023-11-01T06:33:16.086176Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"wrong =[]\nfor item in range(len(theoretical_answers)):\n    temp=[]\n#     print(predict_answer[item]['prediction_text'])\n#     print(theoretical_answers[item]['answers'])\n    if predict_answer[item]['prediction_text'] not in theoretical_answers[item]['answers']['text'][0]  :\n        temp.append(test_data[item])\n#         temp.append(predict[item])\n        wrong.append(temp)\n        ","metadata":{"execution":{"iopub.status.busy":"2023-10-31T08:54:04.325925Z","iopub.execute_input":"2023-10-31T08:54:04.326845Z","iopub.status.idle":"2023-10-31T08:54:04.465855Z","shell.execute_reply.started":"2023-10-31T08:54:04.326805Z","shell.execute_reply":"2023-10-31T08:54:04.464602Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(wrong)","metadata":{"execution":{"iopub.status.busy":"2023-10-31T08:54:11.765319Z","iopub.execute_input":"2023-10-31T08:54:11.765766Z","iopub.status.idle":"2023-10-31T08:54:11.778493Z","shell.execute_reply.started":"2023-10-31T08:54:11.765730Z","shell.execute_reply":"2023-10-31T08:54:11.777174Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open('/kaggle/working/wrong2.json','w') as file:\n    json.dump(wrong,file)","metadata":{"execution":{"iopub.status.busy":"2023-10-31T08:54:24.380138Z","iopub.execute_input":"2023-10-31T08:54:24.380547Z","iopub.status.idle":"2023-10-31T08:54:24.448305Z","shell.execute_reply.started":"2023-10-31T08:54:24.380514Z","shell.execute_reply":"2023-10-31T08:54:24.447050Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"# Predict test data","metadata":{}},{"cell_type":"code","source":"from huggingface_hub import notebook_login\n\nnotebook_login()","metadata":{"execution":{"iopub.status.busy":"2023-11-02T06:57:17.755548Z","iopub.execute_input":"2023-11-02T06:57:17.756353Z","iopub.status.idle":"2023-11-02T06:57:17.780723Z","shell.execute_reply.started":"2023-11-02T06:57:17.756320Z","shell.execute_reply":"2023-11-02T06:57:17.779435Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import json\nfrom datasets import Dataset, load_dataset, load_metric\nimport pandas as pd\nwith open('/kaggle/input/uitds-fever-ise-publist-test/ise-dsc01-public-test-offcial.json', 'r') as file:\n    datasets = json.load(file)","metadata":{"execution":{"iopub.status.busy":"2023-11-02T06:57:29.959259Z","iopub.execute_input":"2023-11-02T06:57:29.959665Z","iopub.status.idle":"2023-11-02T06:57:30.365631Z","shell.execute_reply.started":"2023-11-02T06:57:29.959631Z","shell.execute_reply":"2023-11-02T06:57:30.364511Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open('/kaggle/input/uitds-fever-ise-publist-test/ise-dsc01-public-test-offcial.json', 'r') as file:\n    test_set = json.load(file)","metadata":{"execution":{"iopub.status.busy":"2023-11-02T06:57:30.368161Z","iopub.execute_input":"2023-11-02T06:57:30.368991Z","iopub.status.idle":"2023-11-02T06:57:30.536283Z","shell.execute_reply.started":"2023-11-02T06:57:30.368952Z","shell.execute_reply":"2023-11-02T06:57:30.535162Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_set['id']","metadata":{"execution":{"iopub.status.busy":"2023-10-31T09:26:28.709598Z","iopub.execute_input":"2023-10-31T09:26:28.709990Z","iopub.status.idle":"2023-10-31T09:26:28.772139Z","shell.execute_reply.started":"2023-10-31T09:26:28.709960Z","shell.execute_reply":"2023-10-31T09:26:28.769364Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"not_id =[7135, 7133, 11179, 10152, 10073,10036, 9993,9914, 9835,9676, 9597, 9360, 9281, 9123, 9044, 8886, 8807, 8254, 8096, 31185]","metadata":{"execution":{"iopub.status.busy":"2023-10-18T16:58:56.188096Z","iopub.execute_input":"2023-10-18T16:58:56.188473Z","iopub.status.idle":"2023-10-18T16:58:56.192395Z","shell.execute_reply.started":"2023-10-18T16:58:56.188448Z","shell.execute_reply":"2023-10-18T16:58:56.191774Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"idset = [ str(item) for item in test_set['id'] if item not in not_id]","metadata":{"execution":{"iopub.status.busy":"2023-10-18T16:58:59.626633Z","iopub.execute_input":"2023-10-18T16:58:59.626960Z","iopub.status.idle":"2023-10-18T16:58:59.631111Z","shell.execute_reply.started":"2023-10-18T16:58:59.626937Z","shell.execute_reply":"2023-10-18T16:58:59.630529Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_datasets = {key: datasets[key] for key in idset}","metadata":{"execution":{"iopub.status.busy":"2023-10-18T16:59:00.995763Z","iopub.execute_input":"2023-10-18T16:59:00.996402Z","iopub.status.idle":"2023-10-18T16:59:01.000624Z","shell.execute_reply.started":"2023-10-18T16:59:00.996368Z","shell.execute_reply":"2023-10-18T16:59:00.999741Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_datasets = test_set","metadata":{"execution":{"iopub.status.busy":"2023-11-02T06:57:33.723918Z","iopub.execute_input":"2023-11-02T06:57:33.724844Z","iopub.status.idle":"2023-11-02T06:57:33.729166Z","shell.execute_reply.started":"2023-11-02T06:57:33.724807Z","shell.execute_reply":"2023-11-02T06:57:33.728119Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(test_datasets)","metadata":{"execution":{"iopub.status.busy":"2023-11-02T06:57:33.911951Z","iopub.execute_input":"2023-11-02T06:57:33.912378Z","iopub.status.idle":"2023-11-02T06:57:33.919519Z","shell.execute_reply.started":"2023-11-02T06:57:33.912348Z","shell.execute_reply":"2023-11-02T06:57:33.918376Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Processed test data","metadata":{}},{"cell_type":"code","source":"import re\n\n\ndef remove_author_from_context(context, author):\n    if context.endswith(author):\n        context = context[: -len(author)].strip()\n    return context\n\ndef processed_based_data(datasets):\n    new_datasets = {}\n    for key, item in datasets.items():\n        context = item['context']\n        author_pattern = r\"\\n\\n(.+)$\"\n        author_match = re.search(author_pattern, context)\n    #     print(author_match)\n\n        if author_match:\n            author = author_match.group(1)\n    #         print(author,\"\\n\")\n            if len(author) < 50:\n                item['context'] = remove_author_from_context(context, author)\n    #             print(author,'\\n')\n            if item['evidence'] is None:                  \n                item['context'] = re.sub(r'\\n\\n', ' ', item['context'])\n                item['context'] = \" \".join(item['context'].split())\n\n                new_datasets[key] = item\n                continue\n            if author in item['evidence']:\n                continue\n\n            item['evidence'] = re.sub(r'\\n\\n', ' ', item['evidence'])\n            item['evidence'] = \" \".join(item['evidence'].split())\n\n            item['context'] = re.sub(r'\\n\\n', ' ', item['context'])\n            item['context'] = \" \".join(item['context'].split())\n\n            new_datasets[key] = item\n        else:\n            # If no author found, just process evidence (if exists) and context\n            if item['evidence'] is not None:\n                item['evidence'] = re.sub(r'\\n\\n', ' ', item['evidence'])\n                item['evidence'] = \" \".join(item['evidence'].split())\n\n            item['context'] = re.sub(r'\\n\\n', ' ', item['context'])\n            item['context'] = \" \".join(item['context'].split())\n\n            new_datasets[key] = item\n    return new_datasets\n","metadata":{"execution":{"iopub.status.busy":"2023-11-02T03:12:34.434955Z","iopub.execute_input":"2023-11-02T03:12:34.435323Z","iopub.status.idle":"2023-11-02T03:12:34.447333Z","shell.execute_reply.started":"2023-11-02T03:12:34.435291Z","shell.execute_reply":"2023-11-02T03:12:34.446370Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_datasets = processed_based_data(test_datasets)","metadata":{"execution":{"iopub.status.busy":"2023-11-02T03:12:36.263396Z","iopub.execute_input":"2023-11-02T03:12:36.264010Z","iopub.status.idle":"2023-11-02T03:12:36.692730Z","shell.execute_reply.started":"2023-11-02T03:12:36.263976Z","shell.execute_reply":"2023-11-02T03:12:36.691424Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import re\n\n\ndef remove_author_from_context(context, author):\n    if context.endswith(author):\n        context = context[: -len(author)].strip()\n    return context\n\ndef processed_testset_data(datasets):\n    new_datasets = {}\n    for key, item in datasets.items():\n        context = item['context']\n        author_pattern = r\"\\n\\n(.+)$\"\n        author_match = re.search(author_pattern, context)\n    #     print(author_match)\n\n        if author_match:\n            author = author_match.group(1)\n    #         print(author,\"\\n\")\n            if len(author) < 50:\n                item['context'] = remove_author_from_context(context, author)\n    #             print(author,'\\n')\n#             if item['evidence'] is None:                  \n                item['context'] = re.sub(r'\\n\\n', ' ', item['context'])\n                item['context'] = \" \".join(item['context'].split())\n\n                new_datasets[key] = item\n                continue\n#             if author in item['evidence']:\n#                 continue\n\n#             item['evidence'] = re.sub(r'\\n\\n', ' ', item['evidence'])\n#             item['evidence'] = \" \".join(item['evidence'].split())\n\n            item['context'] = re.sub(r'\\n\\n', ' ', item['context'])\n            item['context'] = \" \".join(item['context'].split())\n\n            new_datasets[key] = item\n        else:\n            # If no author found, just process evidence (if exists) and context\n#             if item['evidence'] is not None:\n#                 item['evidence'] = re.sub(r'\\n\\n', ' ', item['evidence'])\n#                 item['evidence'] = \" \".join(item['evidence'].split())\n\n            item['context'] = re.sub(r'\\n\\n', ' ', item['context'])\n            item['context'] = \" \".join(item['context'].split())\n\n            new_datasets[key] = item\n    return new_datasets\n","metadata":{"execution":{"iopub.status.busy":"2023-11-02T06:57:45.658790Z","iopub.execute_input":"2023-11-02T06:57:45.659152Z","iopub.status.idle":"2023-11-02T06:57:45.670359Z","shell.execute_reply.started":"2023-11-02T06:57:45.659125Z","shell.execute_reply":"2023-11-02T06:57:45.669257Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_datasets = processed_testset_data(test_datasets)","metadata":{"execution":{"iopub.status.busy":"2023-11-02T06:57:45.993346Z","iopub.execute_input":"2023-11-02T06:57:45.993700Z","iopub.status.idle":"2023-11-02T06:57:46.891105Z","shell.execute_reply.started":"2023-11-02T06:57:45.993674Z","shell.execute_reply":"2023-11-02T06:57:46.890009Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test_datasets","metadata":{"execution":{"iopub.status.busy":"2023-11-02T03:12:41.387479Z","iopub.execute_input":"2023-11-02T03:12:41.388198Z","iopub.status.idle":"2023-11-02T03:12:41.392212Z","shell.execute_reply.started":"2023-11-02T03:12:41.388166Z","shell.execute_reply":"2023-11-02T03:12:41.391299Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for key, item in test_datasets.items():\n    item['id'] = key\n    item['context'] = item['context'].replace(\"…\",\"... \")\n    item['context'] = item['context'].replace(\"\\\"\",\" \\\"\")\n    \n#     context = item['context']\n#     if item['evidence'] is not None:\n#         item['evidence_start'] = context.find(item['evidence'])","metadata":{"execution":{"iopub.status.busy":"2023-11-02T06:57:48.898528Z","iopub.execute_input":"2023-11-02T06:57:48.898966Z","iopub.status.idle":"2023-11-02T06:57:48.933083Z","shell.execute_reply.started":"2023-11-02T06:57:48.898931Z","shell.execute_reply":"2023-11-02T06:57:48.931918Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test_datasets","metadata":{"execution":{"iopub.status.busy":"2023-10-22T11:35:31.194551Z","iopub.execute_input":"2023-10-22T11:35:31.194953Z","iopub.status.idle":"2023-10-22T11:35:31.199960Z","shell.execute_reply.started":"2023-10-22T11:35:31.194912Z","shell.execute_reply":"2023-10-22T11:35:31.198877Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"keys_to_delete = []\nfor key, item in test_datasets.items():\n    if item['evidence'] is None:\n        continue\n    if item['claim'] in item['context'] and item['claim'] not in item['evidence']:\n        keys_to_delete.append(key)\n\nfor key in keys_to_delete:\n    del test_datasets[key]","metadata":{"execution":{"iopub.status.busy":"2023-10-18T16:59:49.446583Z","iopub.execute_input":"2023-10-18T16:59:49.446898Z","iopub.status.idle":"2023-10-18T16:59:49.455217Z","shell.execute_reply.started":"2023-10-18T16:59:49.446875Z","shell.execute_reply":"2023-10-18T16:59:49.454308Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"refutes_data = []\nsupport_data = []\nnot_enough_data = []\n\nfor key, item in test_datasets.items():\n    verdict = item['verdict']\n    if verdict == 'REFUTED':\n        refutes_data.append(item)\n    elif verdict == 'SUPPORTED':\n        support_data.append(item)\n    elif verdict == 'NEI':\n        not_enough_data.append(item)","metadata":{"execution":{"iopub.status.busy":"2023-10-18T20:10:24.536755Z","iopub.execute_input":"2023-10-18T20:10:24.537304Z","iopub.status.idle":"2023-10-18T20:10:24.579736Z","shell.execute_reply.started":"2023-10-18T20:10:24.537273Z","shell.execute_reply":"2023-10-18T20:10:24.578799Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_2_class = refutes_data + support_data","metadata":{"execution":{"iopub.status.busy":"2023-10-18T17:04:29.425071Z","iopub.execute_input":"2023-10-18T17:04:29.425437Z","iopub.status.idle":"2023-10-18T17:04:29.430521Z","shell.execute_reply.started":"2023-10-18T17:04:29.425408Z","shell.execute_reply":"2023-10-18T17:04:29.429756Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install transformers sentence-transformers numpy","metadata":{"execution":{"iopub.status.busy":"2023-11-02T06:57:53.545839Z","iopub.execute_input":"2023-11-02T06:57:53.546794Z","iopub.status.idle":"2023-11-02T06:58:11.487129Z","shell.execute_reply.started":"2023-11-02T06:57:53.546760Z","shell.execute_reply":"2023-11-02T06:58:11.485685Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoTokenizer, AutoModel\nfrom sentence_transformers import SentenceTransformer, util\nimport numpy as np\nimport torch","metadata":{"execution":{"iopub.status.busy":"2023-11-02T06:58:11.489513Z","iopub.execute_input":"2023-11-02T06:58:11.489891Z","iopub.status.idle":"2023-11-02T06:58:16.384436Z","shell.execute_reply.started":"2023-11-02T06:58:11.489856Z","shell.execute_reply":"2023-11-02T06:58:16.383253Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"phobert_model_name = \"vinai/phobert-base\"\ntokenizer = AutoTokenizer.from_pretrained(phobert_model_name)\nmodel = AutoModel.from_pretrained(phobert_model_name)","metadata":{"execution":{"iopub.status.busy":"2023-11-02T06:58:16.385930Z","iopub.execute_input":"2023-11-02T06:58:16.386645Z","iopub.status.idle":"2023-11-02T06:58:30.480187Z","shell.execute_reply.started":"2023-11-02T06:58:16.386612Z","shell.execute_reply":"2023-11-02T06:58:30.479254Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test_datasets","metadata":{"execution":{"iopub.status.busy":"2023-11-02T07:23:36.314386Z","iopub.execute_input":"2023-11-02T07:23:36.315185Z","iopub.status.idle":"2023-11-02T07:23:36.319858Z","shell.execute_reply.started":"2023-11-02T07:23:36.315145Z","shell.execute_reply":"2023-11-02T07:23:36.318514Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom torch.cuda.amp import autocast\nfrom tqdm.auto import tqdm\n\ndef process_data_with_gpu(data, tokenizer, model, max_context_sentences=6):\n    # Đảm bảo GPU có sẵn\n    device = torch.device(\"cuda\")\n    model = model.to(device)\n\n    processed_data = []\n    simi_data = []\n\n    for item in tqdm(data.values()):\n        claim = item['claim']\n        context = item['context']\n        claim_tokens = tokenizer(claim, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n        with torch.no_grad():\n            with autocast():  # Sử dụng autocast để tận dụng hiệu suất và giảm bộ nhớ\n                claim_embedding = model(**claim_tokens).pooler_output\n\n        # Di chuyển tensors lên CPU để thực hiện các phép toán NumPy\n        claim_embedding = claim_embedding.to(\"cpu\").numpy()\n\n        # Chuyển các tensors về kiểu float32 (32-bit floating point)\n        claim_embedding = claim_embedding.astype('float32')\n        context_sentences = extract_sentences_offcial(context)# Tách các câu trong context\n        best_similarity = 0.3  # Điểm tương đồng cao nhất\n        # Câu có điểm tương đồng cao nhất\n        best_sentence = []   \n        for sentence in context_sentences:\n            # Tiến hành nhúng câu\n            similarity = []\n            sentence_tokens = tokenizer(sentence, return_tensors=\"pt\", padding=True, truncation=True).to(device)\n            with torch.no_grad():\n                sentence_embedding = model(**sentence_tokens).pooler_output\n            sentence_embedding = sentence_embedding.to(\"cpu\").numpy()\n\n            # Chuyển các tensors về kiểu float32 (32-bit floating point)\n            sentence_embedding = sentence_embedding.astype('float32')\n\n            # Tính độ tương tự với câu claim\n            similarity_score = util.pytorch_cos_sim(claim_embedding, sentence_embedding)\n            if len(context_sentences) <= max_context_sentences:\n                similarity.append(similarity_score.item())\n                similarity.append(sentence)\n                best_sentence.append(similarity)\n                continue \n\n            if similarity_score.item() > best_similarity:\n                similarity.append(similarity_score.item())\n                similarity.append(sentence)\n                best_sentence.append(similarity)\n\n        sorted_data = sorted(best_sentence, key=lambda x: x[0], reverse=True)\n        top_data = sorted_data\n        if len(top_data) >1 and top_data[0][0] >= 0.9:\n            data = {\n                \"context\": context,\n                \"claim\": claim,\n    #             \"verdict\": item['verdict'],\n                \"evidence\": top_data[0][1],\n                \"id\": item['id']\n            }\n            simi_data.append(data)\n            continue\n        if len(top_data) <=6:\n            context_end = context\n        else:\n            context_end = \". \".join([item[1] for item in top_data])\n        words = re.findall(r'\\b\\w+\\b', claim)\n        # Tính tổng số từ trong câu\n        total_words = len(words)\n\n        # Tính điểm chia dựa trên tỷ lệ 40% và 60% của tổng số từ\n        split_point = int(total_words * 0.4)\n\n        # Chia câu thành 40% và 60% dựa trên từ\n        part_40 = \" \".join(words[:split_point])\n        part_60 = \" \".join(words[split_point:])\n        data = {\n            \"context\": context_end,\n            \"claim\": part_60,\n#             \"verdict\": item['verdict'],\n#             \"evidence\": item['evidence'],\n            \"id\": item['id']\n        }\n\n        processed_data.append(data)\n\n    return processed_data, simi_data\n","metadata":{"execution":{"iopub.status.busy":"2023-11-02T07:42:23.345843Z","iopub.execute_input":"2023-11-02T07:42:23.346664Z","iopub.status.idle":"2023-11-02T07:42:23.367032Z","shell.execute_reply.started":"2023-11-02T07:42:23.346628Z","shell.execute_reply":"2023-11-02T07:42:23.365700Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_2_class, simi_predict = process_data_with_gpu(test_datasets, tokenizer, model)","metadata":{"execution":{"iopub.status.busy":"2023-11-02T07:42:27.232632Z","iopub.execute_input":"2023-11-02T07:42:27.233823Z","iopub.status.idle":"2023-11-02T08:08:39.420412Z","shell.execute_reply.started":"2023-11-02T07:42:27.233763Z","shell.execute_reply":"2023-11-02T08:08:39.419238Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(test_2_class)","metadata":{"execution":{"iopub.status.busy":"2023-11-02T08:11:46.455995Z","iopub.execute_input":"2023-11-02T08:11:46.457247Z","iopub.status.idle":"2023-11-02T08:11:46.464360Z","shell.execute_reply.started":"2023-11-02T08:11:46.457203Z","shell.execute_reply":"2023-11-02T08:11:46.463240Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(simi_predict)","metadata":{"execution":{"iopub.status.busy":"2023-11-02T08:12:03.732553Z","iopub.execute_input":"2023-11-02T08:12:03.733602Z","iopub.status.idle":"2023-11-02T08:12:03.741495Z","shell.execute_reply.started":"2023-11-02T08:12:03.733548Z","shell.execute_reply":"2023-11-02T08:12:03.740382Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_copy = test_2_class.copy()","metadata":{"execution":{"iopub.status.busy":"2023-11-02T08:12:08.804131Z","iopub.execute_input":"2023-11-02T08:12:08.805026Z","iopub.status.idle":"2023-11-02T08:12:08.809196Z","shell.execute_reply.started":"2023-11-02T08:12:08.804993Z","shell.execute_reply":"2023-11-02T08:12:08.808078Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"combined_text = []\nfor item in test_copy:\n    combined_text.append(item['context'] + \" \" + item['claim'])\nseq_len = [len(i.split()) for i in combined_text]\nchart = pd.Series(seq_len)\nprint(chart)\nchart.hist(bins=30)\nmin_seq_len = min(seq_len)\nprint(\"Minimum sequence length:\", min_seq_len)","metadata":{"execution":{"iopub.status.busy":"2023-11-02T08:12:10.478125Z","iopub.execute_input":"2023-11-02T08:12:10.479019Z","iopub.status.idle":"2023-11-02T08:12:11.106976Z","shell.execute_reply.started":"2023-11-02T08:12:10.478984Z","shell.execute_reply":"2023-11-02T08:12:11.105691Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test_copy","metadata":{"execution":{"iopub.status.busy":"2023-11-02T08:12:14.195519Z","iopub.execute_input":"2023-11-02T08:12:14.196432Z","iopub.status.idle":"2023-11-02T08:12:14.200867Z","shell.execute_reply.started":"2023-11-02T08:12:14.196396Z","shell.execute_reply":"2023-11-02T08:12:14.199562Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"combined_text = []\nmin_seq_len = float('inf')  # Khởi tạo độ dài tối thiểu là vô cùng lớn\n\nfor item in test_copy:\n    context = item['context']\n    combined_text.append(context)\n    seq_len = len(context.split())  # Độ dài của câu\n    \n    if seq_len < min_seq_len:\n        min_seq_len = seq_len\n        min_seq_len_id = item['id']\n\nchart = pd.Series(seq_len)\nprint(chart)\nchart.hist(bins=30)\n\nprint(\"Minimum sequence length:\", min_seq_len)\nprint(\"ID of the sentence with the minimum length:\", min_seq_len_id)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-02T08:12:14.713171Z","iopub.execute_input":"2023-11-02T08:12:14.713611Z","iopub.status.idle":"2023-11-02T08:12:15.260751Z","shell.execute_reply.started":"2023-11-02T08:12:14.713581Z","shell.execute_reply":"2023-11-02T08:12:15.259699Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for item in test_copy:\n    context = item['context']\n    if item['evidence'] is None:\n        continue\n    item['evidence_start'] = context.find(item['evidence'])\n    ","metadata":{"execution":{"iopub.status.busy":"2023-11-01T15:14:56.035417Z","iopub.execute_input":"2023-11-01T15:14:56.035783Z","iopub.status.idle":"2023-11-01T15:14:57.161239Z","shell.execute_reply.started":"2023-11-01T15:14:56.035753Z","shell.execute_reply":"2023-11-01T15:14:57.159745Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for item in test_copy:\n    item['question'] = item.pop('claim')\n#     if item['evidence'] is None:\n#         item['answers'] = None\n#         continue\n#     item['answers'] = {\n#         'answer_start': [item.pop('evidence_start')],\n#         'text': [item.pop('evidence')]      \n#     }","metadata":{"execution":{"iopub.status.busy":"2023-11-02T08:12:19.273831Z","iopub.execute_input":"2023-11-02T08:12:19.274871Z","iopub.status.idle":"2023-11-02T08:12:19.282009Z","shell.execute_reply.started":"2023-11-02T08:12:19.274834Z","shell.execute_reply":"2023-11-02T08:12:19.280625Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(test_copy)","metadata":{"execution":{"iopub.status.busy":"2023-11-02T08:12:20.639267Z","iopub.execute_input":"2023-11-02T08:12:20.639654Z","iopub.status.idle":"2023-11-02T08:12:20.645779Z","shell.execute_reply.started":"2023-11-02T08:12:20.639624Z","shell.execute_reply":"2023-11-02T08:12:20.644892Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = pd.DataFrame(test_copy)","metadata":{"execution":{"iopub.status.busy":"2023-11-02T08:12:22.468306Z","iopub.execute_input":"2023-11-02T08:12:22.469368Z","iopub.status.idle":"2023-11-02T08:12:22.480011Z","shell.execute_reply.started":"2023-11-02T08:12:22.469319Z","shell.execute_reply":"2023-11-02T08:12:22.479001Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test = Dataset.from_pandas(test)","metadata":{"execution":{"iopub.status.busy":"2023-11-02T08:12:22.709619Z","iopub.execute_input":"2023-11-02T08:12:22.710357Z","iopub.status.idle":"2023-11-02T08:12:22.820899Z","shell.execute_reply.started":"2023-11-02T08:12:22.710322Z","shell.execute_reply":"2023-11-02T08:12:22.819747Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from transformers import AutoTokenizer, XLMRobertaForQuestionAnswering","metadata":{"execution":{"iopub.status.busy":"2023-11-02T08:12:23.066753Z","iopub.execute_input":"2023-11-02T08:12:23.067452Z","iopub.status.idle":"2023-11-02T08:12:23.077782Z","shell.execute_reply.started":"2023-11-02T08:12:23.067417Z","shell.execute_reply":"2023-11-02T08:12:23.076745Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"trained_checkpoint = \"FuuToru/XLMbert-finetuned-squad\"\ntokenizer = AutoTokenizer.from_pretrained(trained_checkpoint)\ntrained_model = XLMRobertaForQuestionAnswering.from_pretrained(trained_checkpoint)","metadata":{"execution":{"iopub.status.busy":"2023-11-02T08:12:23.493156Z","iopub.execute_input":"2023-11-02T08:12:23.494137Z","iopub.status.idle":"2023-11-02T08:12:43.362659Z","shell.execute_reply.started":"2023-11-02T08:12:23.494098Z","shell.execute_reply":"2023-11-02T08:12:43.361612Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"max_length =512\nstride =30\ndef preprocess_test_examples(examples):\n    questions = [q.strip() for q in examples[\"question\"]]\n    inputs = tokenizer(\n        questions,\n        examples[\"context\"],\n        max_length=max_length,\n        truncation=\"only_second\",\n        stride=True,\n        return_overflowing_tokens=True,\n        return_offsets_mapping=True,\n        padding=\"max_length\",\n    )\n\n    sample_map = inputs.pop(\"overflow_to_sample_mapping\")\n    example_ids = []\n\n    for i in range(len(inputs[\"input_ids\"])):\n        sample_idx = sample_map[i]\n        example_ids.append(examples[\"id\"][sample_idx])\n\n        sequence_ids = inputs.sequence_ids(i)\n        offset = inputs[\"offset_mapping\"][i]\n        inputs[\"offset_mapping\"][i] = [\n            o if sequence_ids[k] == 1 else None for k, o in enumerate(offset)\n        ]\n\n    inputs[\"example_id\"] = example_ids\n    return inputs","metadata":{"execution":{"iopub.status.busy":"2023-11-02T08:12:43.364823Z","iopub.execute_input":"2023-11-02T08:12:43.365659Z","iopub.status.idle":"2023-11-02T08:12:43.374696Z","shell.execute_reply.started":"2023-11-02T08:12:43.365617Z","shell.execute_reply":"2023-11-02T08:12:43.373534Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test_dataset = test.map(\n    preprocess_test_examples,\n    batched=True,\n    remove_columns=test.column_names,\n)\nlen(test), len(test_dataset)","metadata":{"execution":{"iopub.status.busy":"2023-11-02T08:12:43.375835Z","iopub.execute_input":"2023-11-02T08:12:43.376167Z","iopub.status.idle":"2023-11-02T08:17:57.208346Z","shell.execute_reply.started":"2023-11-02T08:12:43.376139Z","shell.execute_reply":"2023-11-02T08:17:57.207243Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nfrom transformers import AutoModelForQuestionAnswering\n\ntest_set_for_model = test_dataset.remove_columns([\"example_id\", \"offset_mapping\"])\ntest_set_for_model.set_format(\"torch\")\n\ndevice = torch.device(\"cuda\") if torch.cuda.is_available() else torch.device(\"cpu\")\ntrained_model = XLMRobertaForQuestionAnswering.from_pretrained(trained_checkpoint).to(\n    device\n)\n\nbatch_size = 4  # Hoặc giảm còn ít hơn\n\n# Chia dữ liệu thành các batch nhỏ hơn\ntotal_samples = len(test_set_for_model[\"input_ids\"])\noutputs = []  # Để tích lũy kết quả từ từng batch\nfor start in tqdm(range(0, total_samples, batch_size)):\n    end = min(start + batch_size, total_samples)\n    batch = {k: test_set_for_model[k][start:end].to(device) for k in test_set_for_model.column_names}\n    with torch.no_grad():\n        output = trained_model(**batch)\n    outputs.append(output)\n","metadata":{"execution":{"iopub.status.busy":"2023-11-02T08:17:57.210237Z","iopub.execute_input":"2023-11-02T08:17:57.210529Z","iopub.status.idle":"2023-11-02T08:59:31.468129Z","shell.execute_reply.started":"2023-11-02T08:17:57.210504Z","shell.execute_reply":"2023-11-02T08:59:31.467002Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import torch\nimport numpy as np\n\nstart_logits = torch.cat([output.start_logits for output in outputs], dim=0).cpu().numpy()\nend_logits = torch.cat([output.end_logits for output in outputs], dim=0).cpu().numpy()","metadata":{"execution":{"iopub.status.busy":"2023-11-02T08:59:44.843470Z","iopub.execute_input":"2023-11-02T08:59:44.844331Z","iopub.status.idle":"2023-11-02T08:59:44.883139Z","shell.execute_reply.started":"2023-11-02T08:59:44.844294Z","shell.execute_reply":"2023-11-02T08:59:44.882150Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(start_logits)","metadata":{"execution":{"iopub.status.busy":"2023-11-02T08:59:45.094778Z","iopub.execute_input":"2023-11-02T08:59:45.095605Z","iopub.status.idle":"2023-11-02T08:59:45.102662Z","shell.execute_reply.started":"2023-11-02T08:59:45.095564Z","shell.execute_reply":"2023-11-02T08:59:45.101372Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from tqdm.auto import tqdm\nimport collections\n\n\ndef compute_metrics(start_logits, end_logits, features, examples):\n    example_to_features = collections.defaultdict(list)\n    for idx, feature in enumerate(features):\n        example_to_features[feature[\"example_id\"]].append(idx)\n    n_best = 20\n    max_answer_length = 400\n    predicted_answers = []\n    for example in tqdm(examples):\n        example_id = example[\"id\"]\n        context = example[\"context\"]\n        sentences = extract_sentences_offcial(context)\n        answers = []\n\n        # Lặp qua tất cả các đặc trưng liên quan tới mẫu đó\n        for feature_index in example_to_features[example_id]:\n            start_logit = start_logits[feature_index]\n            end_logit = end_logits[feature_index]\n            offsets = features[feature_index][\"offset_mapping\"]\n\n            start_indexes = np.argsort(start_logit)[-1 : -n_best - 1 : -1].tolist()\n            end_indexes = np.argsort(end_logit)[-1 : -n_best - 1 : -1].tolist()\n            for start_index in start_indexes:\n                for end_index in end_indexes:\n                    # Bỏ qua câu trả lời không xuất hiện hoàn toàn trong ngữ cảnh\n                    if  (start_index >= len(offsets)\n                        or end_index >= len(offsets)\n                        or offsets[start_index] is None \n                        or offsets[end_index] is None):\n                        continue\n                    # Bỏ qua những câu trả lời với độ dài < 0 hoặc > max_answer_length\n                    if len(offsets[start_index]) == 0 or len(offsets[end_index]) == 0:\n                        continue\n                    if (\n                        end_index <= start_index\n                        or end_index - start_index + 1 > max_answer_length\n                    ):\n                        continue\n\n                    answer = {\n                        \"text\": context[offsets[start_index][0] : offsets[end_index][1]],\n                        \"logit_score\": start_logit[start_index] + end_logit[end_index],\n                    }\n                    answers.append(answer)\n\n        # Chọn câu trả lời có điểm cao nhất\n        if len(answers) > 0:\n            best_answer = max(answers, key=lambda x: x[\"logit_score\"])                \n            predicted_answers.append(\n                {\"id\": example_id,\"context\": context,\"claim\": example['question'], \"evidence\": best_answer['text']}\n            )\n        else:\n            predicted_answers.append({\"id\": example_id,\"context\": context,\"claim\": example['question'], \"evidence\": sentences[0]})\n\n    return predicted_answers\n#     theoretical_answers = [{\"id\": ex[\"id\"], \"answers\": ex[\"answers\"]} for ex in examples]\n#     return metric.compute(predictions=predicted_answers, references=theoretical_answers)","metadata":{"execution":{"iopub.status.busy":"2023-11-02T08:59:59.077715Z","iopub.execute_input":"2023-11-02T08:59:59.078118Z","iopub.status.idle":"2023-11-02T08:59:59.093986Z","shell.execute_reply.started":"2023-11-02T08:59:59.078085Z","shell.execute_reply":"2023-11-02T08:59:59.092789Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"test","metadata":{"execution":{"iopub.status.busy":"2023-11-02T08:59:59.942598Z","iopub.execute_input":"2023-11-02T08:59:59.943634Z","iopub.status.idle":"2023-11-02T08:59:59.951306Z","shell.execute_reply.started":"2023-11-02T08:59:59.943582Z","shell.execute_reply":"2023-11-02T08:59:59.950066Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predict = compute_metrics(start_logits, end_logits, test_dataset, test)","metadata":{"execution":{"iopub.status.busy":"2023-11-02T09:00:00.309836Z","iopub.execute_input":"2023-11-02T09:00:00.310357Z","iopub.status.idle":"2023-11-02T09:02:30.284141Z","shell.execute_reply.started":"2023-11-02T09:00:00.310315Z","shell.execute_reply":"2023-11-02T09:02:30.282896Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# predict","metadata":{"execution":{"iopub.status.busy":"2023-11-02T09:03:34.166515Z","iopub.execute_input":"2023-11-02T09:03:34.167212Z","iopub.status.idle":"2023-11-02T09:03:34.171825Z","shell.execute_reply.started":"2023-11-02T09:03:34.167141Z","shell.execute_reply":"2023-11-02T09:03:34.170532Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from sklearn.feature_extraction.text import TfidfVectorizer\nfrom sklearn.metrics.pairwise import cosine_similarity\n\ndef get_similarity_with_TF_IDF_Sklearn(claim, evidence):\n    \n    # Tạo một TF-IDF Vectorizer\n    tfidf_vectorizer = TfidfVectorizer()\n\n    # Biểu diễn câu thành vector TF-IDF\n    tfidf_matrix = tfidf_vectorizer.fit_transform([claim, evidence])\n\n    # Tính toán cosine similarity\n    cosine_sim = cosine_similarity(tfidf_matrix[0], tfidf_matrix[1])\n\n    return cosine_sim[0][0]","metadata":{"execution":{"iopub.status.busy":"2023-11-02T09:03:36.723626Z","iopub.execute_input":"2023-11-02T09:03:36.724051Z","iopub.status.idle":"2023-11-02T09:03:36.730825Z","shell.execute_reply.started":"2023-11-02T09:03:36.724018Z","shell.execute_reply":"2023-11-02T09:03:36.729618Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for item in predict:\n    context = item['context']\n    sentences = extract_sentences_offcial(context) \n    answer = item['evidence']\n    sentences_answers = extract_sentences_offcial(answer)\n    if(len(sentences_answers)>1):\n        temp = -1\n        ans =\"\"\n        for sent in sentences_answers:\n            simi = get_similarity_with_TF_IDF_Sklearn(item['claim'], sent)\n            if simi > temp:\n                temp = simi\n                ans =sent\n        for sent in sentences:\n            if ans in sent or sent in ans:\n                item['evidence'] = sent\n                break               \n    for sent in sentences:\n        if sentences_answers[0] in sent or sent in sentences_answers[0]:\n            item['evidence'] = sent\n            break\n    ","metadata":{"execution":{"iopub.status.busy":"2023-11-02T09:03:38.010077Z","iopub.execute_input":"2023-11-02T09:03:38.011020Z","iopub.status.idle":"2023-11-02T09:03:40.552000Z","shell.execute_reply.started":"2023-11-02T09:03:38.010985Z","shell.execute_reply":"2023-11-02T09:03:40.550966Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# test_datasets\nmy_list = [ value for value in test_datasets.values()]\n\n","metadata":{"execution":{"iopub.status.busy":"2023-11-02T09:07:37.991751Z","iopub.execute_input":"2023-11-02T09:07:37.992499Z","iopub.status.idle":"2023-11-02T09:07:37.997731Z","shell.execute_reply.started":"2023-11-02T09:07:37.992463Z","shell.execute_reply":"2023-11-02T09:07:37.996588Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for item in predict:\n    idd = item['id']\n    for item2 in my_list:\n        if idd == item2['id']:\n            item['claim'] =item2['claim']\n            break\n    ","metadata":{"execution":{"iopub.status.busy":"2023-11-02T09:11:27.549901Z","iopub.execute_input":"2023-11-02T09:11:27.551114Z","iopub.status.idle":"2023-11-02T09:11:28.937908Z","shell.execute_reply.started":"2023-11-02T09:11:27.551072Z","shell.execute_reply":"2023-11-02T09:11:28.936730Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"predict_final = simi_predict + predict","metadata":{"execution":{"iopub.status.busy":"2023-11-02T09:12:36.049934Z","iopub.execute_input":"2023-11-02T09:12:36.050842Z","iopub.status.idle":"2023-11-02T09:12:36.055575Z","shell.execute_reply.started":"2023-11-02T09:12:36.050803Z","shell.execute_reply":"2023-11-02T09:12:36.054445Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(predict_final)","metadata":{"execution":{"iopub.status.busy":"2023-11-02T09:12:44.475689Z","iopub.execute_input":"2023-11-02T09:12:44.476654Z","iopub.status.idle":"2023-11-02T09:12:44.484374Z","shell.execute_reply.started":"2023-11-02T09:12:44.476609Z","shell.execute_reply":"2023-11-02T09:12:44.483012Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# Hàm chuyển đổi kiểu dữ liệu không thể chuyển đổi sang JSON\ndef custom_converter(obj):\n    if isinstance(obj, np.float32):\n        return float(obj)  # Chuyển đổi np.float32 sang float\n    else:\n        raise TypeError(f\"Object of type {obj.__class__.__name__} is not JSON serializable\")\ntype(predict)\n\noutput_file_path = \"predict-evidence.json\"\n\n# Sử dụng hàm custom_converter để ghi dữ liệu vào tập tin JSON\nwith open(output_file_path, \"w\", encoding=\"utf-8\") as output_file:\n    json.dump(predict_final, output_file, ensure_ascii=False, indent=4, default=custom_converter)","metadata":{"execution":{"iopub.status.busy":"2023-11-02T09:12:51.719634Z","iopub.execute_input":"2023-11-02T09:12:51.720025Z","iopub.status.idle":"2023-11-02T09:12:52.038373Z","shell.execute_reply.started":"2023-11-02T09:12:51.719996Z","shell.execute_reply":"2023-11-02T09:12:52.037194Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"with open('/kaggle/working/predict-evidence.json','r') as file:\n    read = json.load(file)","metadata":{"execution":{"iopub.status.busy":"2023-10-18T22:22:09.165473Z","iopub.execute_input":"2023-10-18T22:22:09.166066Z","iopub.status.idle":"2023-10-18T22:22:09.290593Z","shell.execute_reply.started":"2023-10-18T22:22:09.166036Z","shell.execute_reply":"2023-10-18T22:22:09.289855Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"len(read)","metadata":{"execution":{"iopub.status.busy":"2023-10-18T22:22:14.036287Z","iopub.execute_input":"2023-10-18T22:22:14.036886Z","iopub.status.idle":"2023-10-18T22:22:14.041875Z","shell.execute_reply.started":"2023-10-18T22:22:14.036859Z","shell.execute_reply":"2023-10-18T22:22:14.041318Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"!pip install evaluate","metadata":{"execution":{"iopub.status.busy":"2023-10-19T15:36:49.019572Z","iopub.execute_input":"2023-10-19T15:36:49.019977Z","iopub.status.idle":"2023-10-19T15:36:58.200499Z","shell.execute_reply.started":"2023-10-19T15:36:49.019945Z","shell.execute_reply":"2023-10-19T15:36:58.199081Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"import evaluate\n\nmetric = evaluate.load(\"squad\")","metadata":{"execution":{"iopub.status.busy":"2023-10-18T17:09:07.940848Z","iopub.execute_input":"2023-10-18T17:09:07.941088Z","iopub.status.idle":"2023-10-18T17:09:08.832137Z","shell.execute_reply.started":"2023-10-18T17:09:07.941067Z","shell.execute_reply":"2023-10-18T17:09:08.831387Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"theoretical_answers = [\n    {\"id\": ex[\"id\"], \"answers\": ex[\"answers\"]} for ex in test\n]","metadata":{"execution":{"iopub.status.busy":"2023-10-18T17:09:17.283619Z","iopub.execute_input":"2023-10-18T17:09:17.283940Z","iopub.status.idle":"2023-10-18T17:09:17.333184Z","shell.execute_reply.started":"2023-10-18T17:09:17.283917Z","shell.execute_reply":"2023-10-18T17:09:17.332517Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"for item in range(len(theoretical_answers)): \n    print(\"Predict: \",predict[item])\n    print(\"Theoretical: \",theoretical_answers[item])\n    print(\"\\n------------------------------------------\\n\")","metadata":{"execution":{"iopub.status.busy":"2023-10-18T17:13:42.250783Z","iopub.execute_input":"2023-10-18T17:13:42.251117Z","iopub.status.idle":"2023-10-18T17:13:42.304052Z","shell.execute_reply.started":"2023-10-18T17:13:42.251094Z","shell.execute_reply":"2023-10-18T17:13:42.303443Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# metric.compute(predictions=predict, references=theoretical_answers)","metadata":{"execution":{"iopub.status.busy":"2023-10-18T17:15:23.719309Z","iopub.execute_input":"2023-10-18T17:15:23.719671Z","iopub.status.idle":"2023-10-18T17:15:23.723590Z","shell.execute_reply.started":"2023-10-18T17:15:23.719640Z","shell.execute_reply":"2023-10-18T17:15:23.722727Z"},"trusted":true},"execution_count":null,"outputs":[]}]}